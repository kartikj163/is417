{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "black-friday",
   "metadata": {},
   "source": [
    "# HW7: Contingency tables\n",
    "\n",
    "We'll use simple 2x2 contingency tables to explore overrepresented words (using Dunning's log-likelihood a.k.a a G-test), and then use a contingency table of a similar form to dramatize the importance of distinguishing \"recall\" from \"precision\" in classification.\n",
    "\n",
    "We'll start by importing some familiar modules, as well as \"display\" which will allow us to directly print dataframes. We're also importing a function called ```chi2_contingency``` that we will eventually use to calculate Dunning's log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caroline-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, random, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from scipy.stats import chi2_contingency\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-running",
   "metadata": {},
   "source": [
    "## Dunning's log likelihood\n",
    "\n",
    "Ultimately our goal here is to explore a more principled way of identifying \"overrepresented words\" than the simple ratio tests we were using earlier in the course.\n",
    "\n",
    "We'll start by reading in the familiar movie-characters dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reliable-advisory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>cid</th>\n",
       "      <th>cname</th>\n",
       "      <th>mname</th>\n",
       "      <th>gender</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>year</th>\n",
       "      <th>genres</th>\n",
       "      <th>comedy</th>\n",
       "      <th>thriller</th>\n",
       "      <th>drama</th>\n",
       "      <th>romance</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>m536</td>\n",
       "      <td>u7921</td>\n",
       "      <td>GENERAL SCHMUCK</td>\n",
       "      <td>dr. strangelove or: how i learned to stop worr...</td>\n",
       "      <td>M</td>\n",
       "      <td>828</td>\n",
       "      <td>1964</td>\n",
       "      <td>['comedy', 'drama']</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>That's right, fella. / See!  See, I told you. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>m303</td>\n",
       "      <td>u4593</td>\n",
       "      <td>JONAS</td>\n",
       "      <td>conspiracy theory</td>\n",
       "      <td>m</td>\n",
       "      <td>555</td>\n",
       "      <td>1997</td>\n",
       "      <td>['action', 'crime', 'mystery', 'romance', 'thr...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Liza Sutton is dead. / You shouldn't watch, Je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>m214</td>\n",
       "      <td>u3238</td>\n",
       "      <td>OVERLORD</td>\n",
       "      <td>the time machine</td>\n",
       "      <td>M</td>\n",
       "      <td>421</td>\n",
       "      <td>2002</td>\n",
       "      <td>['sci-fi', 'adventure', 'action']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>And why not? / But you've earned a reward for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>m363</td>\n",
       "      <td>u5452</td>\n",
       "      <td>LILLIAN</td>\n",
       "      <td>game 6</td>\n",
       "      <td>f</td>\n",
       "      <td>165</td>\n",
       "      <td>2005</td>\n",
       "      <td>['comedy', 'drama', 'sport']</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>I'm glad we're having this talk. / I never tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>m113</td>\n",
       "      <td>u1725</td>\n",
       "      <td>YNYR</td>\n",
       "      <td>krull</td>\n",
       "      <td>m</td>\n",
       "      <td>1173</td>\n",
       "      <td>1983</td>\n",
       "      <td>['fantasy', 'action', 'adventure', 'sci-fi']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I can. Because I choose it. / It is my fate to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mid    cid            cname  \\\n",
       "2355  m536  u7921  GENERAL SCHMUCK   \n",
       "1145  m303  u4593            JONAS   \n",
       "652   m214  u3238         OVERLORD   \n",
       "1445  m363  u5452          LILLIAN   \n",
       "96    m113  u1725             YNYR   \n",
       "\n",
       "                                                  mname gender  wordcount  \\\n",
       "2355  dr. strangelove or: how i learned to stop worr...      M        828   \n",
       "1145                                  conspiracy theory      m        555   \n",
       "652                                    the time machine      M        421   \n",
       "1445                                             game 6      f        165   \n",
       "96                                                krull      m       1173   \n",
       "\n",
       "      year                                             genres  comedy  \\\n",
       "2355  1964                                ['comedy', 'drama']    True   \n",
       "1145  1997  ['action', 'crime', 'mystery', 'romance', 'thr...   False   \n",
       "652   2002                  ['sci-fi', 'adventure', 'action']   False   \n",
       "1445  2005                       ['comedy', 'drama', 'sport']    True   \n",
       "96    1983       ['fantasy', 'action', 'adventure', 'sci-fi']   False   \n",
       "\n",
       "      thriller  drama  romance  \\\n",
       "2355     False   True    False   \n",
       "1145      True  False     True   \n",
       "652      False  False    False   \n",
       "1445     False   True    False   \n",
       "96       False  False    False   \n",
       "\n",
       "                                                  lines  \n",
       "2355  That's right, fella. / See!  See, I told you. ...  \n",
       "1145  Liza Sutton is dead. / You shouldn't watch, Je...  \n",
       "652   And why not? / But you've earned a reward for ...  \n",
       "1445  I'm glad we're having this talk. / I never tho...  \n",
       "96    I can. Because I choose it. / It is my fate to...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogpath = Path('../data/movie_dialogue.tsv')\n",
    "\n",
    "chars = pd.read_csv(dialogpath, sep = '\\t')\n",
    "\n",
    "# let's also randomize the row order\n",
    "chars = chars.sample(frac = 1)\n",
    "chars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-niagara",
   "metadata": {},
   "source": [
    "To frame a useful question: How does movie dialogue change across time? What counts as \"old-fashioned\" or \"classic\" language in the movies?\n",
    "\n",
    "Let's distinguish two groups of films, not by using the *median* year for characters--which we've already calculated as somewhere in the 1990s--but the actual midpoint of the timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assured-round",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1968.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(max(chars['year']) + min(chars['year'])) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-fisher",
   "metadata": {},
   "source": [
    "Let's construct two lists of character IDs based on release date of the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "focused-leonard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 358 classic characters and\n",
      "2611 more recent characters.\n"
     ]
    }
   ],
   "source": [
    "classics = chars.loc[chars['year'] < 1968.5, 'cid']\n",
    "recents = chars.loc[chars['year'] > 1968.5, 'cid']\n",
    "\n",
    "print('We have ' + str(len(classics)) + ' classic characters and')\n",
    "print(str(len(recents)) + ' more recent characters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-bleeding",
   "metadata": {},
   "source": [
    "What words are used especially in older movies?\n",
    "\n",
    "We've explored several casual ways of answering that question, but a more rigorous way to pose it is Dunning's log-likelihood. You may remember that early in the course we read [Ben Schmidt's intuitive explanation of why Dunning's is better than a simple ratio, or simple subtraction.](http://sappingattention.blogspot.com/2011/10/comparing-corpuses-by-word-use.html) But we didn't learn how to actually calculate it in Python.\n",
    "\n",
    "In form, Dunning's test works very much like a chi-squared test for the difference of two proportions. In both cases you begin by constructing a simple *contingency table.*\n",
    "\n",
    "But before we can do that we need to\n",
    "\n",
    "#### generate the term-doc matrix for movie characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "integral-builder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2969, 3359)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'cid' in chars.columns:         \n",
    "    character_ids = chars['cid']\n",
    "    chars = chars.set_index('cid')   # If we haven't made char-id the index yet, let's do it.\n",
    "else:\n",
    "    character_ids = chars.index.tolist()\n",
    "\n",
    "vectorizer = CountVectorizer(min_df = 0.01)  # this limits the table to words present in\n",
    "                                             # at least 1% of characters\n",
    "\n",
    "chars.reset_index(inplace = True)\n",
    "    \n",
    "sparse_counts = vectorizer.fit_transform(chars['lines']) # the vectorizer produces something\n",
    "                                                               # called a 'sparse matrix'; we need to\n",
    "                                                               # unpack it\n",
    "        \n",
    "wordcounts = pd.DataFrame(sparse_counts.toarray(), index = character_ids, \n",
    "                            columns = vectorizer.get_feature_names())\n",
    "wordcounts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "measured-revelation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yourselves</th>\n",
       "      <th>youth</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>u7921</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u4593</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u3238</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u5452</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u1725</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3359 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       000  10  100  11  12  15  18  20  24  25  ...  younger  your  yours  \\\n",
       "cid                                              ...                         \n",
       "u7921    0   0    0   0   0   0   0   0   0   0  ...        0     2      0   \n",
       "u4593    0   0    0   0   0   0   0   0   0   0  ...        0     3      0   \n",
       "u3238    0   0    0   0   0   0   0   0   0   0  ...        0     3      1   \n",
       "u5452    0   0    0   0   0   0   0   0   0   0  ...        0     1      0   \n",
       "u1725    0   0    0   0   0   0   0   0   0   0  ...        0     6      1   \n",
       "\n",
       "       yourself  yourselves  youth  yup  zero  zone  zoo  \n",
       "cid                                                       \n",
       "u7921         0           0      0    0     0     0    0  \n",
       "u4593         1           0      0    0     0     0    0  \n",
       "u3238         0           0      0    0     0     0    0  \n",
       "u5452         0           0      0    0     0     0    0  \n",
       "u1725         1           0      0    0     0     0    0  \n",
       "\n",
       "[5 rows x 3359 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-feeling",
   "metadata": {},
   "source": [
    "Let's now see whether the word *swell* is overrepresented in old movies.\n",
    "\n",
    "#### building a contingency table\n",
    "\n",
    "Let's start by counting occurrences of \"swell.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "resistant-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "classicswell = wordcounts.loc[classics, 'swell'].sum()\n",
    "recentswell = wordcounts.loc[recents, 'swell'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-eclipse",
   "metadata": {},
   "source": [
    "To do the contingency table we also need to know how many words that aren't \"swell\" appear in both categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "quarterly-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "allclassicwords = wordcounts.loc[classics, ].sum().sum()\n",
    "allrecentwords = wordcounts.loc[recents, ].sum().sum()\n",
    "\n",
    "classicnotswell = allclassicwords - classicswell\n",
    "recentnotswell = allrecentwords - recentswell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-colombia",
   "metadata": {},
   "source": [
    "Now we can build the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "known-count",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swell</th>\n",
       "      <th>not swell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classics</th>\n",
       "      <td>41</td>\n",
       "      <td>287224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recent</th>\n",
       "      <td>51</td>\n",
       "      <td>1893313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          swell  not swell\n",
       "classics     41     287224\n",
       "recent       51    1893313"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_table = pd.DataFrame({'swell': [classicswell, recentswell], \n",
    "                        'not swell': [classicnotswell, recentnotswell]},\n",
    "                      index = ['classics', 'recent'])\n",
    "\n",
    "display(c_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-password",
   "metadata": {},
   "source": [
    "It looks like *swell* is proportionally more common in old movies, even though there are more occurrences in recent movies. But how can we know whether this is a significant difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-maine",
   "metadata": {},
   "source": [
    "The Dunning's log-likelihood formula is\n",
    "\n",
    "$$G = 2\\sum_{i=1}^n O_i \\ln(\\frac{O_i}{E_i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-malta",
   "metadata": {},
   "source": [
    "where $O_i$ is the observed frequency in each of the four cells of the table, and $E_i$ is the expected frequency in each cell under the null hypotheses of even distribution across classes. We calculate *G* by adding up observed times the log of (observed/expected) in each cell.\n",
    "\n",
    "You can start to construct the null contingency table with expected values by calculating the **marginal** frequencies for the observed table, which basically means summing both the rows and the columns.\n",
    "\n",
    "#### marginal frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "approved-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsums = c_table.sum(axis = 'columns')\n",
    "colsums = c_table.sum(axis = 'rows')\n",
    "colsums = colsums.rename('totals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "after-failing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swell</th>\n",
       "      <th>not swell</th>\n",
       "      <th>all words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classics</th>\n",
       "      <td>41</td>\n",
       "      <td>287224</td>\n",
       "      <td>287265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recent</th>\n",
       "      <td>51</td>\n",
       "      <td>1893313</td>\n",
       "      <td>1893364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>92</td>\n",
       "      <td>2180537</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          swell  not swell  all words\n",
       "classics     41     287224   287265.0\n",
       "recent       51    1893313  1893364.0\n",
       "totals       92    2180537        NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e_table = c_table.append(colsums)\n",
    "e_table['all words'] = rowsums\n",
    "display(e_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-feedback",
   "metadata": {},
   "source": [
    "To construct the table of expected counts we need to express one of these margins as a probability. In other words, how likely is it that a given word comes from a classic movie, or a recent movie?\n",
    "\n",
    "#### marginal probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "likely-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swell</th>\n",
       "      <th>not swell</th>\n",
       "      <th>all words</th>\n",
       "      <th>marginal probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classics</th>\n",
       "      <td>41</td>\n",
       "      <td>287224</td>\n",
       "      <td>287265.0</td>\n",
       "      <td>0.131735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recent</th>\n",
       "      <td>51</td>\n",
       "      <td>1893313</td>\n",
       "      <td>1893364.0</td>\n",
       "      <td>0.868265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>92</td>\n",
       "      <td>2180537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          swell  not swell  all words  marginal probs\n",
       "classics     41     287224   287265.0        0.131735\n",
       "recent       51    1893313  1893364.0        0.868265\n",
       "totals       92    2180537        NaN             NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e_table['marginal probs'] = rowsums / np.sum(rowsums)\n",
    "display(e_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-winner",
   "metadata": {},
   "source": [
    "Now by multiplying both of the \"totals\" (counts of words in swell / notswell classes) by these marginal probabilities, we can construct a table of the expected distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abandoned-jamaica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swell</th>\n",
       "      <th>not swell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>classics</th>\n",
       "      <td>12.119613</td>\n",
       "      <td>2.872529e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recent</th>\n",
       "      <td>79.880387</td>\n",
       "      <td>1.893284e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              swell     not swell\n",
       "classics  12.119613  2.872529e+05\n",
       "recent    79.880387  1.893284e+06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "expected = colsums.apply(lambda r: r * e_table['marginal probs'][0:2])\n",
    "expected = expected.transpose()\n",
    "display(expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-education",
   "metadata": {},
   "source": [
    "Now we can apply the formula for G to calculate it. Because I really love putting LaTeX math notation in markdown, let's have that formula again!\n",
    "\n",
    "$$G = 2\\sum_{i=1}^n O_i \\ln(\\frac{O_i}{E_i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "empty-alfred",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.17271712337733"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = 0\n",
    "\n",
    "for film_cat in ['classics', 'recent']:\n",
    "    for word_cat in ['swell', 'not swell']:\n",
    "        observe = c_table.loc[film_cat, word_cat]\n",
    "        expect = expected.loc[film_cat, word_cat]\n",
    "        G += 2 * observe * math.log(observe/expect)\n",
    "G   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-kitchen",
   "metadata": {},
   "source": [
    "Which is a step-by-step explanation of what happens when we use this sklearn function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "formal-correlation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.51615912666403 4.26722744688518e-13\n",
      "[[1.21196132e+01 2.87252880e+05]\n",
      " [7.98803868e+01 1.89328412e+06]]\n"
     ]
    }
   ],
   "source": [
    "G, p, dof, ex = chi2_contingency(c_table, lambda_ = 'log-likelihood')\n",
    "print(G, p)\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-familiar",
   "metadata": {},
   "source": [
    "The G value is very slightly different; I'm not sure but I *think* that's simply because the sklearn implementation is approximating. The sklearn version also calculates a p-value for us, so we know this divergence would be very unlikely to happen in a world where \"swell\" was actually equally common in both classes.\n",
    "\n",
    "If we want to sort words by overrepresentation in one category or the other, we'll need to add a sign, because the log-likelihood test itself only tells us how *far* this distribution is from the null model — not which direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "otherwise-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_dunnings(wordcounts, catA, catB):\n",
    "    Asum = wordcounts.loc[catA, ].sum().sum()\n",
    "    Bsum = wordcounts.loc[catB, ].sum().sum()\n",
    "    \n",
    "    tuples = []\n",
    "    for word in wordcounts.columns:\n",
    "        Acount = wordcounts.loc[catA, word].sum()\n",
    "        Bcount = wordcounts.loc[catB, word].sum()\n",
    "        \n",
    "        if Acount < 6 or Bcount < 6:   # it's hard to be confident about the significance\n",
    "            continue                   # of very small numbers\n",
    "            \n",
    "        table = np.array([[Acount, Asum - Acount], [Bcount , Bsum - Bcount]])\n",
    "        G, p, dof, ex = chi2_contingency(table, lambda_ = 'log-likelihood')\n",
    "        \n",
    "        if Acount / Asum < Bcount / Bsum:\n",
    "            G = 0 - G\n",
    "        \n",
    "        tuples.append((G, word))\n",
    "\n",
    "    tuples.sort()\n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "continuing-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlywords = signed_dunnings(wordcounts, classics, recents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-dependence",
   "metadata": {},
   "source": [
    "#### in-class\n",
    "\n",
    "Explore that list of tuples to see what vocabulary distinguishes early movies. \n",
    "\n",
    "### QUESTION 1\n",
    "\n",
    "Use the same technique to find vocabulary that characterizes comedies. Just the high end will do: 25 words *over*represented in comedies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-matrix",
   "metadata": {},
   "source": [
    "## Recall and precision in classification of imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-framing",
   "metadata": {},
   "source": [
    "I'm going to set up a logistic-regression model of early movies, using code borrowed from the March 15th \"Word Vectors\" lab.\n",
    "\n",
    "Then I'll ask you to calculate recall and precision using a contingency table like the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "industrial-strap",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yourselves</th>\n",
       "      <th>youth</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>u7921</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u4593</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u3238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u5452</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u1725</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3359 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       000   10  100   11   12   15   18   20   24   25  ...  younger  \\\n",
       "cid                                                      ...            \n",
       "u7921  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "u4593  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "u3238  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "u5452  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "u1725  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "\n",
       "           your     yours  yourself  yourselves  youth  yup  zero  zone  zoo  \n",
       "cid                                                                           \n",
       "u7921  0.002759  0.000000  0.000000         0.0    0.0  0.0   0.0   0.0  0.0  \n",
       "u4593  0.006424  0.000000  0.002141         0.0    0.0  0.0   0.0   0.0  0.0  \n",
       "u3238  0.008310  0.002770  0.000000         0.0    0.0  0.0   0.0   0.0  0.0  \n",
       "u5452  0.007299  0.000000  0.000000         0.0    0.0  0.0   0.0   0.0  0.0  \n",
       "u1725  0.005709  0.000951  0.000951         0.0    0.0  0.0   0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 3359 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowsums = wordcounts.sum(axis = 'columns')\n",
    "frequencies = wordcounts.divide(rowsums, axis = 'rows')\n",
    "frequencies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-cabinet",
   "metadata": {},
   "source": [
    "You'll recall that logistic regression works best when features are \"scaled\": each column is transformed by subtracting the column mean and dividing by column standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "heavy-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_normed = scaler.fit_transform(frequencies)\n",
    "y = chars['year'] < 1968.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-banks",
   "metadata": {},
   "source": [
    "Because our classes are pretty imbalanced (there are more recent movies than classic films), we'll tune this model to maximize the f1 score, which reflects both recall and precision.\n",
    "\n",
    "In order to do that, we make a couple of crucial decisions below. The class_weight parameter sets the *importance* of each example in the regression to be *inversely* proportional to class size, so it costs more to be wrong about rare classes.\n",
    "\n",
    "We also set a scoring parameter that reports the f1 score rather than simple accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_param in [10, 1, .1, .02, .01, .005, .001, .0001, .00001, .000001]:\n",
    "    balanced_logreg = LogisticRegression(C = c_param, max_iter = 1000, class_weight = 'balanced') # note the class weight\n",
    "    grouper = GroupKFold(n_splits = 10)\n",
    "    cv_results = cross_validate(balanced_logreg, X_normed, y, \n",
    "                                groups = chars['mid'], cv = grouper, scoring = 'f1')  # note the scoring\n",
    "    mean_score = np.mean(cv_results['test_score'])\n",
    "    print(c_param, mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-script",
   "metadata": {},
   "source": [
    "The F1 score, reported above, can be expressed mathematically in several ways:\n",
    "\n",
    "$$2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$$\n",
    "\n",
    "or alternately\n",
    "\n",
    "$$\\frac{\\text{tp}}{\\text{tp} + \\frac{1}{2} (\\text{fp} + \\text{fn})}$$\n",
    "\n",
    "Why do we need to use this complex measure?\n",
    "\n",
    "To understand intuitively why we need it, let's look at the number of true positives (correctly identified classic movies) when we tune the model in different ways. \n",
    "\n",
    "We can start by getting the predictions from the best model above, and comparing them to the real class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "defined-hartford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True, False, False, False, False,\n",
       "        True])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_logreg = LogisticRegression(C = .0001, max_iter = 1000, class_weight = 'balanced')\n",
    "\n",
    "predictions = cross_val_predict(balanced_logreg, X_normed, y, groups = chars['mid'], cv = grouper, method='predict')\n",
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "composed-consequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "8    False\n",
       "9     True\n",
       "Name: year, dtype: bool"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-chair",
   "metadata": {},
   "source": [
    "### QUESTION 2\n",
    "\n",
    "Using those two sequences, produce a contingency table of the form below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "successful-translator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted classic</th>\n",
       "      <th>predicted not classic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actually classic</th>\n",
       "      <td>true positives</td>\n",
       "      <td>false negatives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actually not classic</th>\n",
       "      <td>false positives</td>\n",
       "      <td>true negatives</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     predicted classic predicted not classic\n",
       "actually classic        true positives       false negatives\n",
       "actually not classic   false positives        true negatives"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_c_table = pd.DataFrame({'predicted classic': ['true positives', 'false positives'], \n",
    "                        'predicted not classic': ['false negatives', 'true negatives']},\n",
    "                      index = ['actually classic', 'actually not classic'])\n",
    "\n",
    "display(dummy_c_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-professor",
   "metadata": {},
   "source": [
    "Note that the code we used to create a table for Dunning's is not really very useful here, because your data is in a completely different format (two lists). The only similarity is that the result can in both cases take the form of a 2x2 contingency table.\n",
    "\n",
    "Then calculate recall, precision, and f1 score for this table. You can look up formulas for each of these, but for easy reference.\n",
    "\n",
    "$$\\text{precision} = \\frac{tp}{tp + fp}$$\n",
    "\n",
    "$$\\text{recall} = \\frac{tp}{tp + fn}$$\n",
    "\n",
    "The formula for f1 is provided a few cells above. Your final f1 score should come out fairly close to the f1 score calculated above when we optimized the c parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-management",
   "metadata": {},
   "source": [
    "### QUESTION 3\n",
    "\n",
    "Try tuning a model without the special parameters we used above to handle imbalanced classes; that is,\n",
    "\n",
    "    class_weight = 'balanced')\n",
    "    scoring = 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-crystal",
   "metadata": {},
   "source": [
    "Your new model will treat both classes equally, and will try to maximize accuracy, which is the default scoring criterion. Get the predictions from this model, and produce another contingency table. How many true positives does the new model give you?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
