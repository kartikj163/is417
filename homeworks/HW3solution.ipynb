{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fatty-jacket",
   "metadata": {},
   "source": [
    "# Homework 3: film dialogue\n",
    "\n",
    "In our lab for Feb 15 we looked at two different ways to compare collections of texts: by examining specific words that are overrepresented in one collection relative to another, or by assessing the strength of a model that attempts to describe the boundary between the two.\n",
    "\n",
    "We'll pursue both of those strategies a little further in this homework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-fifty",
   "metadata": {},
   "source": [
    "## Familiar preparation\n",
    "\n",
    "To start with we'll import useful modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "welcome-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-twelve",
   "metadata": {},
   "source": [
    "#### read in the dialogue dataset\n",
    "\n",
    "It has one line for each character; the field ```lines``` contains all dialogue attributed to that character in the [Cornell Movie Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html). Separate lines are delimited by slashes, but we'll ignore that here.\n",
    "\n",
    "We call the dataset ```chars``` because the it has one line per character.\n",
    "\n",
    "Notice that the path below has changed because the ```homeworks/``` directory is only one level down from the parent is417 directory. ```labs/Feb15Dialog/``` was two levels down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "olympic-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogpath = Path('../data/movie_dialogue.tsv')\n",
    "\n",
    "chars = pd.read_csv(dialogpath, sep = '\\t')\n",
    "\n",
    "# let's also randomize the row order\n",
    "chars = chars.sample(frac = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "infectious-eight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>cid</th>\n",
       "      <th>cname</th>\n",
       "      <th>mname</th>\n",
       "      <th>gender</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>year</th>\n",
       "      <th>genres</th>\n",
       "      <th>comedy</th>\n",
       "      <th>thriller</th>\n",
       "      <th>drama</th>\n",
       "      <th>romance</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>m353</td>\n",
       "      <td>u5327</td>\n",
       "      <td>TITA</td>\n",
       "      <td>five easy pieces</td>\n",
       "      <td>f</td>\n",
       "      <td>607</td>\n",
       "      <td>1970</td>\n",
       "      <td>['drama']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Bye, Robert. / But what about me? / You were g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>m145</td>\n",
       "      <td>u2265</td>\n",
       "      <td>ROACH</td>\n",
       "      <td>next friday</td>\n",
       "      <td>m</td>\n",
       "      <td>279</td>\n",
       "      <td>2000</td>\n",
       "      <td>['comedy']</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Fuck, what's his name? / Dude, dogs hate me.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>m564</td>\n",
       "      <td>u8292</td>\n",
       "      <td>DEBORAH</td>\n",
       "      <td>the lost son</td>\n",
       "      <td>f</td>\n",
       "      <td>1309</td>\n",
       "      <td>1999</td>\n",
       "      <td>['crime', 'drama', 'romance', 'thriller']</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>I... We have to bury Leon tommorrow... / You w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>m96</td>\n",
       "      <td>u1430</td>\n",
       "      <td>LINDA</td>\n",
       "      <td>invaders from mars</td>\n",
       "      <td>f</td>\n",
       "      <td>393</td>\n",
       "      <td>1953</td>\n",
       "      <td>['horror', 'sci-fi']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Why, yes.  Why? / He was upset with moving, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>m557</td>\n",
       "      <td>u8208</td>\n",
       "      <td>NOVAK</td>\n",
       "      <td>the cell</td>\n",
       "      <td>m</td>\n",
       "      <td>722</td>\n",
       "      <td>2000</td>\n",
       "      <td>['drama', 'fantasy', 'horror', 'sci-fi', 'thri...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>No problem. / I got it. / I don't know.  I thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mid    cid    cname               mname gender  wordcount  year  \\\n",
       "1400  m353  u5327     TITA    five easy pieces      f        607  1970   \n",
       "255   m145  u2265    ROACH         next friday      m        279  2000   \n",
       "2507  m564  u8292  DEBORAH        the lost son      f       1309  1999   \n",
       "2954   m96  u1430    LINDA  invaders from mars      f        393  1953   \n",
       "2477  m557  u8208    NOVAK            the cell      m        722  2000   \n",
       "\n",
       "                                                 genres  comedy  thriller  \\\n",
       "1400                                          ['drama']   False     False   \n",
       "255                                          ['comedy']    True     False   \n",
       "2507          ['crime', 'drama', 'romance', 'thriller']   False      True   \n",
       "2954                               ['horror', 'sci-fi']   False     False   \n",
       "2477  ['drama', 'fantasy', 'horror', 'sci-fi', 'thri...   False      True   \n",
       "\n",
       "      drama  romance                                              lines  \n",
       "1400   True    False  Bye, Robert. / But what about me? / You were g...  \n",
       "255   False    False  Fuck, what's his name? / Dude, dogs hate me.  ...  \n",
       "2507   True     True  I... We have to bury Leon tommorrow... / You w...  \n",
       "2954  False    False  Why, yes.  Why? / He was upset with moving, I ...  \n",
       "2477   True    False  No problem. / I got it. / I don't know.  I thi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-resource",
   "metadata": {},
   "source": [
    "## A better way to validate models\n",
    "\n",
    "In our lab, we spent a lot of energy selecting test sets and training sets. We learned that if you want to produce a truly general model of a category like \"comedy,\" it's important to make sure your algorithm can't \"cheat\" by just memorizing (say) the names of characters who appear in a limited set of comedies.\n",
    "\n",
    "Defining train and test sets so they contain non-overlapping groups of movies produced a more general model of comedy, and a more realistic estimate of accuracy.\n",
    "\n",
    "But each of us got a slightly different measure of model accuracy, because our measure of accuracy depended entirely on a small subset of the data (1/5th of the movies) that we randomly chose as the test set.\n",
    "\n",
    "To get a more stable measure of accuracy, it's better to *cross-validate* your model, by repeatedly holding out a different 1/5th (or 1/10th) of the data as the test set, and training on the remainder. If we hold out a different test set each time we can eventually test on all the data, without ever testing on data that was included in our training set.\n",
    "\n",
    "We could do this ourselves by writing a loop, but scikit-learn also comes with a ```cross_validate()``` function that does it for us automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pressing-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-badge",
   "metadata": {},
   "source": [
    "First we need to create a matrix of ```wordcounts``` that we'll use to make predictions, and define a useful function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "patient-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cid' in chars.columns:         \n",
    "    character_ids = chars['cid']\n",
    "    chars = chars.set_index('cid')   # If we haven't made this the index yet, let's do it.\n",
    "else:\n",
    "    character_ids = chars.index.tolist()\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 8000)\n",
    "sparse_counts = vectorizer.fit_transform(chars['lines']) # the vectorizer produces something\n",
    "                                                               # called a 'sparse matrix'; we need to\n",
    "                                                               # unpack it\n",
    "wordcounts = pd.DataFrame(sparse_counts.toarray(), index = character_ids, \n",
    "                            columns = vectorizer.get_feature_names())\n",
    "wordcounts.head()\n",
    "\n",
    "# We'll also define a useful function\n",
    "\n",
    "def gendertonumber(astring):\n",
    "    if astring.lower() == 'f':  # note that we lowercase before checking:\n",
    "        return 1                    # this version of the function is slightly\n",
    "    else:                           # better than the one in the lab notebook\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-metallic",
   "metadata": {},
   "source": [
    "Having done that, we can proceed to train models.\n",
    "\n",
    "In the lines below we cross-validate a model of romance, while making sure that the data is grouped by movie-id. If you're curious about GroupKFold (or any other aspect of scikit-learn), you can always [inspect the documentation.](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) Basically, what's happening here is that we define an object that splits the data up into five parts, and then instruct it to use movie-id to do the splitting.\n",
    "\n",
    "What happens if you change the number of splits (```n_splits```) to 10, or to 2? If you see slight changes in accuracy, reflect on why they're happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "helpful-congo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6850795759733364"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y = chars['romance'].astype(int)\n",
    "bayes = MultinomialNB(alpha = 1)\n",
    "grouper = GroupKFold(n_splits = 5)\n",
    "cv_results = cross_validate(bayes, wordcounts, all_y, groups = chars['mid'], cv = grouper)\n",
    "np.mean(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-router",
   "metadata": {},
   "source": [
    "The ```cross_validate()``` function produces a different test_score for each of the five separate test sets. Above, we take the mean score, but we can also inspect them individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "enhanced-hepatitis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.58093619, 0.55154705, 0.52368212, 0.52169085, 0.55365086]),\n",
       " 'score_time': array([0.08528686, 0.06697512, 0.06687689, 0.06704617, 0.06641507]),\n",
       " 'test_score': array([0.66666667, 0.67676768, 0.6986532 , 0.6969697 , 0.68634064])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-lightweight",
   "metadata": {},
   "source": [
    "Notice that if we take out the ```groups``` and ```cv``` parameters it no longer divides the test and training sets by movie-id. In that case, we get an unrealistically high accuracy for genre, because genre becomes easy to predict if you can memorize the vocabulary of specific movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "solved-reason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8201509189704804"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y = chars['romance'].astype(int)\n",
    "bayes = MultinomialNB(alpha = 1)\n",
    "cv_results = cross_validate(bayes, wordcounts, all_y)\n",
    "np.mean(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-andrew",
   "metadata": {},
   "source": [
    "We can also use this same function to model gender. We just have to change the way the response variable *y* is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "further-cabinet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7322301145235378\n"
     ]
    }
   ],
   "source": [
    "all_y = chars['gender'].map(gendertonumber)\n",
    "bayes = MultinomialNB(alpha = 1)\n",
    "grouper = GroupKFold(n_splits = 5)\n",
    "cv_results = cross_validate(bayes, wordcounts, all_y, groups = chars['mid'], cv = grouper)\n",
    "score = np.mean(cv_results['test_score'])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-wichita",
   "metadata": {},
   "source": [
    "## Assignment 1. Changing the smoothing parameter of the model\n",
    "\n",
    "Write a little loop that tests the gender model above while varying the ```alpha``` parameter of the model.\n",
    "\n",
    "Remember, this is the Laplacian smoothing--a number that gets added to the count of each word to acknowledge that it probably *sometimes* occurs in dialogue spoken by women (or by men), even if not in this sample.\n",
    "\n",
    "Try each of the settings in this list: [0.001, 1, 2, 4, 8, 16, 32, 64]. In each case print ```alpha,``` and the resulting accuracy. Then do the same thing--in a separate cell--for a model of genre (say, romance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abroad-estate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 0.7409917045667467\n",
      "1 0.7322301145235378\n",
      "2 0.7278518745635104\n",
      "4 0.7315589850159834\n",
      "8 0.7551410677886226\n",
      "16 0.6972115761323181\n",
      "32 0.6803720169656089\n",
      "64 0.6803714491741473\n"
     ]
    }
   ],
   "source": [
    "for a in [0.001, 1, 2, 4, 8, 16, 32, 64]:\n",
    "    all_y = chars['gender'].map(gendertonumber)\n",
    "    bayes = MultinomialNB(alpha = a)\n",
    "    grouper = GroupKFold(n_splits = 5)\n",
    "    cv_results = cross_validate(bayes, wordcounts, all_y, groups = chars['mid'], cv = grouper)\n",
    "    score = np.mean(cv_results['test_score'])\n",
    "    print(a, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stuck-dimension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 0.7123602523265256\n",
      "1 0.6850795759733364\n",
      "2 0.6810386041414709\n",
      "4 0.6972058982177026\n",
      "8 0.7342542910839707\n",
      "16 0.760516917346597\n",
      "32 0.7621981478642523\n",
      "64 0.7625348482009527\n"
     ]
    }
   ],
   "source": [
    "for a in [0.001, 1, 2, 4, 8, 16, 32, 64]:\n",
    "    all_y = chars['romance'].astype(int)\n",
    "    bayes = MultinomialNB(alpha = a)\n",
    "    grouper = GroupKFold(n_splits = 5)\n",
    "    cv_results = cross_validate(bayes, wordcounts, all_y, groups = chars['mid'], cv = grouper)\n",
    "    score = np.mean(cv_results['test_score'])\n",
    "    print(a, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-newfoundland",
   "metadata": {},
   "source": [
    "Why might alphas higher than one improve the model? Why is the ideal alpha not the same for every category? (Your answer may be a little speculative; that's okay; speculate.)\n",
    "\n",
    "    Some datasets benefit from more smoothing than others. A naive \"overfit\" model can stray further from the truth, for instance, if the dataset includes a lot of variables, or if some variables have dramatically different frequencies in different subsets of a genre. In a situation like that you might need a lot of smoothing. Also, if the counts of features were simply higher across the board (for instance if the texts were longer), you might need more smoothing.\n",
    "    \n",
    "    More generally, this is an example of what's called \"bias-variance tradeoff\"; optimizing machine learning is a matter of finding a good balance between error within a sample and error *across* samples. And the optimal balance can be different in each dataset. We'll discuss this at more length in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-ladder",
   "metadata": {},
   "source": [
    "## Assignment 2.\n",
    "\n",
    "In the lab on Feb 15 we practiced ways to identify words that are overrepresented in one corpus relative to another.\n",
    "\n",
    "If you review [Ben Schmidt's blog post about comparing corpuses,](http://sappingattention.blogspot.com/2011/10/comparing-corpuses-by-word-use.html), you'll realize that the methods we used in that lab were fairly crude. We were just asking how much larger a word's frequency is in one corpus than in the other, or how many *times* larger its frequency is. As Schmidt's post shows, there may be better ways to make that comparison, and in future weeks we'll explore them.\n",
    "\n",
    "But for right now, let's just practice the simple ratio test. Create a list of 25 words that are many times more common in romances than in other movies, and a list of 25 words that are many times more common in other movies than in romances. Compare these lists to the similar test we performed on gender categories in the lab. The evidence you get from this comparison will not be decisive, but what hypotheses come to mind as deserving further investigation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "solid-regard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bye        101\n",
       "cab         41\n",
       "cabin       15\n",
       "cabinet      9\n",
       "cable        8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romance_counts = wordcounts.loc[chars['romance'] == True, : ].sum(axis = 'rows')\n",
    "romance_counts[1000:1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "graduate-convenience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bye        148\n",
       "cab         74\n",
       "cabin       46\n",
       "cabinet     12\n",
       "cable       38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_counts = wordcounts.loc[chars['romance'] == False, : ].sum(axis = 'rows')\n",
    "other_counts[1000:1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "happy-beach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hildy         0.197714\n",
       "vada          0.221679\n",
       "leon          0.236344\n",
       "wyatt         0.239066\n",
       "sailor        0.241781\n",
       "baxter        0.243076\n",
       "baron         0.243143\n",
       "rick          0.244521\n",
       "jeanne        0.244655\n",
       "lula          0.247143\n",
       "ninotchka     0.250528\n",
       "alvy          0.252256\n",
       "homer         0.253800\n",
       "casablanca    0.254008\n",
       "lombard       0.254008\n",
       "marylin       0.254008\n",
       "barry         0.256288\n",
       "romeo         0.256766\n",
       "preysing      0.257585\n",
       "gallagher     0.257585\n",
       "glenn         0.260917\n",
       "wynant        0.261265\n",
       "lawson        0.261265\n",
       "yuh           0.263145\n",
       "sieu          0.263145\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romance_freqs = (romance_counts + 100) / sum(romance_counts)\n",
    "other_freqs = (other_counts + 100) / sum(other_counts)\n",
    "ratios = other_freqs / romance_freqs\n",
    "ratios = ratios.sort_values()\n",
    "ratios[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "basic-fundamental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paul       1.112681\n",
       "he         1.120457\n",
       "harry      1.123439\n",
       "the        1.123475\n",
       "them       1.126300\n",
       "need       1.133890\n",
       "sir        1.136751\n",
       "goddamn    1.143585\n",
       "man        1.149095\n",
       "jake       1.185098\n",
       "dr         1.192372\n",
       "captain    1.193568\n",
       "we         1.194898\n",
       "our        1.223458\n",
       "ain        1.224317\n",
       "dead       1.230806\n",
       "killed     1.258457\n",
       "they       1.279527\n",
       "fuck       1.419654\n",
       "kill       1.433346\n",
       "us         1.436684\n",
       "hell       1.457556\n",
       "shit       1.527525\n",
       "fucking    1.537658\n",
       "fuckin     1.695847\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios[-25: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "frequent-married",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>romance</th>\n",
       "      <th>mid</th>\n",
       "      <th>cname</th>\n",
       "      <th>mname</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>year</th>\n",
       "      <th>genres</th>\n",
       "      <th>comedy</th>\n",
       "      <th>thriller</th>\n",
       "      <th>drama</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>False</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>True</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m</td>\n",
       "      <td>False</td>\n",
       "      <td>1573</td>\n",
       "      <td>1573</td>\n",
       "      <td>1573</td>\n",
       "      <td>1573</td>\n",
       "      <td>1573</td>\n",
       "      <td>1573</td>\n",
       "      <td>1573</td>\n",
       "      <td>1573</td>\n",
       "      <td>1573</td>\n",
       "      <td>1573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m</td>\n",
       "      <td>True</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  romance   mid  cname  mname  wordcount  year  genres  comedy  \\\n",
       "0      f    False   691    691    691        691   691     691     691   \n",
       "1      f     True   258    258    258        258   258     258     258   \n",
       "2      m    False  1573   1573   1573       1573  1573    1573    1573   \n",
       "3      m     True   447    447    447        447   447     447     447   \n",
       "\n",
       "   thriller  drama  lines  \n",
       "0       691    691    691  \n",
       "1       258    258    258  \n",
       "2      1573   1573   1573  \n",
       "3       447    447    447  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars['gender'] = chars.gender.str.lower()\n",
    "chars.groupby(['gender', 'romance'], as_index = False).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-anime",
   "metadata": {},
   "source": [
    "## Assignment 3: do gender stereotypes weaken over time?\n",
    "\n",
    "It probably doesn't make sense to try to answer this question with a single big model of all movies, because the gender norms involved in shaping dialogue could have *changed* over time.\n",
    "\n",
    "Instead, let's find the median release date for characters, and divide our dataset into two roughly evenly-sized groups (early and late). Then we can cross-validate models to predict gender in each half of the dataset, and see if the accuracy of the later model is lower.\n",
    "\n",
    "In the lab notebook, I proposed running this test many times, in order to measure uncertainty, and draw inferences about significance. But the technique of \"sampling with replacement\" may require more explanation. I'll demonstrate a way to do that in the homework solution, but for right now just cross-validate a single model for each half of the timeline -- using the methods from assignment 1 -- and see what result you get.\n",
    "\n",
    "You may want to try different values of \"alpha,\" as we did in Assignment 1, and use the value that performs best for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "persistent-shame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1995.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(chars['year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-ethernet",
   "metadata": {},
   "source": [
    "#### A simple solution\n",
    "\n",
    "This is what I hoped you would be able to do: split the data into two parts, and run a model on each part. We could use the alpha setting (8) that we identified as optimal for gender earlier. If you did that, it's reasonable.\n",
    "\n",
    "But ideally we would check the optimal setting on a dataset closer in size to the one we'll be using: roughly half of the chars dataset, or 1484 characters. The optimal level of smoothing can be highly dependent on the size of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "matched-insured",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.7195252070252071\n",
      "2 0.7349940849940849\n",
      "3 0.750503913003913\n",
      "4 0.7575717763217763\n",
      "5 0.7321491946491947\n",
      "6 0.7254214441714442\n",
      "7 0.7110929110929111\n",
      "8 0.6971096096096097\n",
      "9 0.6859950859950859\n"
     ]
    }
   ],
   "source": [
    "for alpha in range(1, 10):\n",
    "    \n",
    "    # to get a good measure of accuracy at different alpha settings,\n",
    "    # we'll try four different random samples at each setting\n",
    "    \n",
    "    fourscores = []\n",
    "    \n",
    "    for j in range(0, 4):\n",
    "    \n",
    "        chars = chars.sample(frac = 1)\n",
    "        firsthalfchars = chars.iloc[0: 1484 : ]\n",
    "        firsthalfwordcounts = wordcounts.loc[firsthalfchars.index.tolist(), : ]\n",
    "\n",
    "        # model the first half\n",
    "\n",
    "        all_y = firsthalfchars['gender'].map(gendertonumber)\n",
    "        bayes = MultinomialNB(alpha = alpha)\n",
    "        grouper = GroupKFold(n_splits = 5)\n",
    "        cv_results = cross_validate(bayes, firsthalfwordcounts, all_y, groups = firsthalfchars['mid'], cv = grouper)\n",
    "        score = np.mean(cv_results['test_score'])\n",
    "        fourscores.append(score)\n",
    "    \n",
    "    print(i, np.mean(fourscores))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-alcohol",
   "metadata": {},
   "source": [
    "Now use the optimal alpha, which is 4, for both halves of the timeline and observe the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "split-bishop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7586080586080586\n"
     ]
    }
   ],
   "source": [
    "firsthalfchars = chars.loc[chars['year'] < 1994, : ]\n",
    "secondhalfchars = chars.loc[chars['year'] >= 1995, : ]\n",
    "firsthalfwordcounts = wordcounts.loc[firsthalfchars.index.tolist(), : ]\n",
    "secondhalfwordcounts = wordcounts.loc[secondhalfchars.index.tolist(), : ]\n",
    "\n",
    "# model the first half\n",
    "\n",
    "all_y = firsthalfchars['gender'].map(gendertonumber)\n",
    "bayes = MultinomialNB(alpha = 4)\n",
    "grouper = GroupKFold(n_splits = 5)\n",
    "cv_results = cross_validate(bayes, firsthalfwordcounts, all_y, groups = firsthalfchars['mid'], cv = grouper)\n",
    "earlyscore = np.mean(cv_results['test_score'])\n",
    "print(earlyscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "coral-trauma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7422950819672132\n"
     ]
    }
   ],
   "source": [
    "# model the second half\n",
    "\n",
    "all_y = secondhalfchars['gender'].map(gendertonumber)\n",
    "bayes = MultinomialNB(alpha = 4)\n",
    "grouper = GroupKFold(n_splits = 5)\n",
    "cv_results = cross_validate(bayes, secondhalfwordcounts, all_y, groups = secondhalfchars['mid'], cv = grouper)\n",
    "latescore = np.mean(cv_results['test_score'])\n",
    "print(latescore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-hypothesis",
   "metadata": {},
   "source": [
    "#### A more rigorous test\n",
    "\n",
    "That's all I asked you to do. But now let's ask how confident we are in our answer.\n",
    "\n",
    "It *looks* like gender roles become less predictable toward the end of the timeline.\n",
    "\n",
    "But how confident can we be that the difference between .745 and .740 is significant? Could this just be a variation that is likely to occur by chance?\n",
    "\n",
    "There aren't great statistical methods for estimating the significance of a difference like this *a priori.* The best we can do is to randomly resample the data and see how likely we would be to get a difference of this size if both samples were drawn from the same population.\n",
    "\n",
    "We'll draw two samples of the same size as the ones we just created. (Note that the first model, with higher accuracy, was based on a smaller sample.)\n",
    "\n",
    "The exact numbers here will depend on whether you counted 1995 as the last element of the earlier half of the timeline, or the first element of the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "separate-territory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1367, 12)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firsthalfchars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "compliant-argentina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1525, 12)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondhalfchars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "suspended-opposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7287986952220529 0.7545366043613708 -0.02573790913931795\n",
      "0.7478329456431647 0.7551382398753893 -0.007305294232224591\n",
      "0.712769712039785 0.773868769470405 -0.06109905743061994\n",
      "0.7331568674634369 0.7538901869158878 -0.020733319452450938\n",
      "0.7550894361113338 0.7426460280373831 0.012443408073950724\n",
      "0.7368412609288522 0.7520190809968847 -0.015177820068032588\n",
      "0.7478249244672602 0.7451713395638629 0.002653584903397288\n",
      "0.7258549236651427 0.7595229750778817 -0.033668051412738986\n",
      "0.7456084061923478 0.7432963395638629 0.0023120666284849323\n",
      "0.745621774818855 0.7513882398753894 -0.005766465056534331\n",
      "0.7470629127563434 0.7382904984423677 0.008772414313975685\n",
      "0.7346407850057485 0.7614018691588784 -0.026761084153129944\n",
      "0.7470709339322478 0.752684968847352 -0.00561403491510426\n",
      "0.7521750755327398 0.7364154984423675 0.015759577090372234\n",
      "0.7397957273869682 0.7476771806853583 -0.007881453298390073\n",
      "0.7316863185476323 0.7701499221183801 -0.03846360357074774\n",
      "0.7507205689687442 0.7582943925233645 -0.007573823554620329\n",
      "0.7317237507018529 0.7501518691588785 -0.018428118457025633\n",
      "0.7463570492767573 0.7520443925233644 -0.005687343246607135\n",
      "0.7631721076976552 0.7514057632398754 0.011766344457779798\n",
      "0.7258816609181573 0.7526518691588786 -0.026770208240721294\n",
      "0.7470468704045347 0.733921339563863 0.013125530840671695\n",
      "0.7411887382690303 0.7414154984423675 -0.00022676017333722598\n",
      "0.7426993930643565 0.7539154984423677 -0.01121610537801121\n",
      "0.7412128017967434 0.75764992211838 -0.016437120321636578\n",
      "0.7266115879254567 0.7507943925233646 -0.024182804597907892\n",
      "0.7521563594556295 0.7351732866043614 0.0169830728512681\n",
      "0.73318093099115 0.7514232866043613 -0.018242355613211303\n",
      "0.7295794230100799 0.7632690809968847 -0.03368965798680479\n",
      "0.722937889361247 0.7588921339563864 -0.035954244595139406\n",
      "0.7375471244084384 0.7370210280373832 0.0005260963710551625\n",
      "0.7426539397342318 0.7526557632398754 -0.010001823505643603\n",
      "0.7390390631266543 0.7688999221183801 -0.029860858991725747\n",
      "0.733221036870672 0.7470366043613706 -0.013815567490698677\n",
      "0.7478329456431646 0.7464232866043614 0.0014096590388031904\n",
      "0.7361220288227587 0.7539116043613706 -0.017789575538611935\n",
      "0.7587845244779551 0.7414116043613707 0.017372920116584423\n",
      "0.7449052164380632 0.7489232866043614 -0.004018070166298182\n",
      "0.7434132777198471 0.7551693925233645 -0.011756114803517348\n",
      "0.7390390631266543 0.7439077102803738 -0.004868647153719485\n",
      "0.7455896901152376 0.7395307632398754 0.006058926875362136\n",
      "0.7427127616908639 0.7557807632398754 -0.013068001549011554\n",
      "0.7595304938370632 0.7426732866043613 0.0168572072327019\n",
      "0.7361193550974573 0.7451460280373832 -0.009026672939925873\n",
      "0.7617282960348654 0.7539271806853584 0.007801115349507004\n",
      "0.7251356915590492 0.7507710280373832 -0.025635336478333937\n",
      "0.7265768294965376 0.7726401869158878 -0.04606335741935019\n",
      "0.7558113419427288 0.744542445482866 0.011268896459862843\n",
      "0.7470923237346595 0.7526538161993769 -0.005561492464717377\n",
      "0.7682709018475442 0.7407768691588785 0.02749403268866568\n"
     ]
    }
   ],
   "source": [
    "randomscorediffs = []\n",
    "\n",
    "for i in range(50):\n",
    "    shuffledchars = chars.sample(frac = 1)\n",
    "    firsthalfchars = shuffledchars.iloc[0: 1368, : ]\n",
    "    secondhalfchars = shuffledchars.iloc[1368 : , : ]\n",
    "    firsthalfwordcounts = wordcounts.loc[firsthalfchars.index.tolist(), : ]\n",
    "    secondhalfwordcounts = wordcounts.loc[secondhalfchars.index.tolist(), : ]\n",
    "    \n",
    "    # model the first half\n",
    "\n",
    "    all_y = firsthalfchars['gender'].map(gendertonumber)\n",
    "    bayes = MultinomialNB(alpha = 4)\n",
    "    grouper = GroupKFold(n_splits = 5)\n",
    "    cv_results = cross_validate(bayes, firsthalfwordcounts, all_y, groups = firsthalfchars['mid'], cv = grouper)\n",
    "    firstscore = np.mean(cv_results['test_score'])\n",
    "    \n",
    "    # model the second half\n",
    "\n",
    "    all_y = secondhalfchars['gender'].map(gendertonumber)\n",
    "    bayes = MultinomialNB(alpha = 4)\n",
    "    grouper = GroupKFold(n_splits = 5)\n",
    "    cv_results = cross_validate(bayes, secondhalfwordcounts, all_y, groups = secondhalfchars['mid'], cv = grouper)\n",
    "    secondscore = np.mean(cv_results['test_score'])\n",
    "    \n",
    "    scorediff = firstscore - secondscore\n",
    "    \n",
    "    print(firstscore, secondscore, scorediff)\n",
    "    randomscorediffs.append(scorediff)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-plain",
   "metadata": {},
   "source": [
    "So how much variation do we get with totally random splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "disabled-consultancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02749403268866568"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(randomscorediffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "organizational-thomas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06109905743061994"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(randomscorediffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-patent",
   "metadata": {},
   "source": [
    "How big was the difference between halves of the dataset with a chronological split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eleven-airplane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01631297664084541"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chronscorediff = earlyscore - latescore\n",
    "chronscorediff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-christopher",
   "metadata": {},
   "source": [
    "Let's compare the random variation we got (the bell-like curve below) to the actual difference we observed (the vertical red line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "designing-finish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7fe871f82910>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAw5UlEQVR4nO3deXhUZZr///edFbJACAlZSEhYQthBCAiuCIKAC2q74T7T07S22tq7M9090zM98/v19OJ0tzoqrbaKgEu70Yr7BioEwr7JFrKRQBIgIQvZ7+8fKZwYKxCSqjpVyf26rrqq6ixVH4okdz3nPOd5RFUxxhhj2gtyOoAxxhj/ZAXCGGOMW1YgjDHGuGUFwhhjjFtWIIwxxrgV4nQAT4qLi9P09HSnYxhjztaePa33mZnO5uiFNm7cWK6q8e7W9agCkZ6eTk5OjtMxjDFna+bM1vtPPnEyRa8kIvkdrbNDTMYYY9yyAmGMMcYtKxDGGGPcsgJhjDHGLSsQxhhj3LICYYwxxi0rEMYYY9yyAmFMgFBVGppaaG6xIfqNb3jtQjkRSQWeAxKBFmCJqv5JRGKBF4F0IA+4QVWPu9l/HvAnIBh4UlV/462sxvgrVWXV9sO8sqmItQeOcrKxmb6hwUxM7c8NWalcOTGZ0GD7nme8w5s/WU3Aj1R1NDAduEdExgAPAh+qagbwoev514hIMPAoMB8YAyxy7WtMr5FbVs01//sF9yzfxN4jVVw3JYUfzx3JjVNTKa9u4IcvbeWyP65mx6FKp6OaHsprLQhVLQFKXI+rRGQ3MBhYCMx0bfYs8Anws3a7TwP2q2ougIi84Npvl7fyGuNPPtlTyn3LNxMSLPzuuglcOzmF4CD5an1Li/L+7iP82xs7ueZ/P+c3107gW1NSHExseiKfjMUkIunAOUA2kOAqHqhqiYgMcrPLYKCwzfMi4NwOXnsxsBhgyJAhHkxtjDM+3lPK4udyyBgUzZLbp5AyIOIb2wQFCZeNTWRaeiz3rtjEj17eysnGZm6dnuZAYtNTef3gpYhEAa8AD6jqic7u5maZ2zNzqrpEVbNUNSs+3u2AhMYEjI35x7hr6UZGJkSzYvF0t8WhrQGRYTx1x1RmjxrEL17fwdvbS3yU1PQGXi0QIhJKa3FYpqqvuhYfEZEk1/okoNTNrkVAapvnKUCxN7Ma47TSE3Xc/fwmEvv3Yem3z6V/39BO7dcnNJhHb5nM5CEx/OClLWwrqvBuUNNreK1AiIgATwG7VfWhNqtWAne4Ht8BvOFm9w1AhogMFZEw4CbXfsb0SM0tyr0rNlNV18SS27KIjQw7q/37hAaz5PYsBkaGc+/yzVTVNXopqelNvNmCOB+4DZglIltctwXAb4A5IrIPmON6jogki8gqAFVtAu4F3gV2Ay+p6k4vZjXGUU99lsv6g8f4z6vHkZkY3aXXiIsK58+LJnGo4iQ/f22HhxOa3sibvZg+w/25BIDZbrYvBha0eb4KWOWddMb4j/2lVfz+vb1cNjaBaycP7tZrTUmL5f7ZGTz0/l4WjE9k3rgkD6U0vZFdYWOMg1SVn7+2g76hwfzXNeNpPTLbPXfPHM6YpH788o2dVNbaoSbTdVYgjHHQG1uKyT54jJ/OyyQuKtwjrxkaHMR/f2sCR6vr+d17X3rkNU3vZAXCGIfU1Dfx/63azcSU/tw01bPX8IxP6c9t09NYnl3A3iNVHn1t03tYgTDGIU+uOUhpVT3/euWYr10l7SkPXDqSqPAQ/vOt3R5/bdM7WIEwxgFlVfU8sfoA88clMiUt1ivvMSAyjO/PzmD13jI+3uPuciNjTs8KhDEOePTj/TQ0tfDTeaO8+j63z0hnaFwk//XWbhqbW7z6XqbnsQJhjI+VnqhjxfoCrp08mKFxkV59r7CQIP55/ij2l1azYn2BV9/L9DxWIIzxsSWrc2lqUe65ZIRP3m/OmATOHRrLwx/t52RDs0/e0/QMViCM8aGyqnqez85n4aRk0gZ6t/Vwiojwo7mZlFXVsyw73yfvaXoGKxDG+NCTa3JpaGrhXh+1Hk6ZNjSWCzPieOyTA9TUN/n0vU3gsgJhjI8cra7nubX5XDUxmWHxUT5//wcuHcnRmgaeW2utCNM5ViCM8ZG/fp5HXVMz987ybevhlClpA5iZGc8Tqw/YaK+mU6xAGOMDtQ1NLF2Xz5zRCYwY1LXRWj3hB5eOpKK2kWc+z3MsgwkcViCM8YFXNhZRebKR71w0zNEcE1NjuHT0IJ76/CDVdi7CnIEVCGO8rLlFeeqzg0xMjSErbYDTcbhvVgYVtY0stXMR5gysQBjjZR/sPkLe0Vq+c+FQjwzn3V0TU2O4aGQ8T67JpbbBWhGmY96ccvRpESkVkR1tlr3YZna5PBHZ0sG+eSKy3bVdjrcyGuMLT67JZXBMX+aNTXQ6yle+P2sER2saWJ5tV1ebjnmzBfEMMK/tAlW9UVUnqeok4BXg1dPsf4lr2yzvRTTGu7YUVrAh7zj/eMFQQoL9p8GelR7LjGEDeWJ1LnWNdnW1cc9rP7Gquho45m6dtLazbwBWeOv9jfEHf/38INHhIdw4NdXpKN9w3+wRlFXV8+KGQqejGD/l1FeaC4Ejqrqvg/UKvCciG0VksQ9zGeMxZVX1rNpewnVZKUSFe2369y6bMWwgWWkDePzTA9Q3WSvCfJNTBWIRp289nK+qk4H5wD0iclFHG4rIYhHJEZGcsrIyT+c0pste3FBAY7Ny6/Q0p6O4JSLcNzuDkso6Xtl4yOk4xg/5vECISAhwLfBiR9uoarHrvhR4DZh2mm2XqGqWqmbFx8d7Oq4xXdLU3MKy7AIuGBHHcAeG1eisizLimJgaw/9+st/mizDf4EQL4lLgS1UtcrdSRCJFJPrUY2AusMPdtsb4qw92l1JSWcdtM/yz9XCKiPD9WSMoOn6S1zdbK8J8nTe7ua4A1gKZIlIkIt92rbqJdoeXRCRZRFa5niYAn4nIVmA98JaqvuOtnMZ4w9J1eST378PsUYOcjnJGs0YNYmxyP/73kwM0t6jTcYwf8dqZM1Vd1MHyO90sKwYWuB7nAhO9lcsYb9tfWs3n+4/yk8sy/apra0dEhPtmjeCu5zfx5rZiFk4a7HQk4yf8/6fXmADz/Lp8QoOFG7L8r2trR+aOSSQzIZpHPtpPi7UijIsVCGM8qKa+iVc2FrFgfBLx0eFOx+m0oCDhnlkj2FdazTs7Dzsdx/gJKxDGeNDrWw5RVd/E7X5+ctqdy8cnMSw+koc/2o+qtSKMFQhjPEZVWbo2nzFJ/Zg8xPlRW89WcJBwz8wR7C45wQe7S52OY/yAFQhjPGRD3nG+PFzFbTPS/GLU1q5YOCmZIbERPPzRPmtFGCsQxnjK0nX5RPcJYeGkZKejdFlIcBDfmzmcbUWVfLLXRibo7axAGOMBpVV1vLOjhOunpBIR5n/jLp2NayenMDimLw9/aK2I3s4KhDEe8ML6Qhqb1e+vnO6MsJAg7po5nE0FFXxx4KjTcYyDrEAY001NzS0szy7gwow4hsZFOh3HI66fkkJCv3D+/GFHAy6b3sAKhDHd9P6uIxw+Ucdtfjpqa1f0CQ3muxcNJ/vgMdYfdDuti+kFrEAY003Prc1ncExfZo9OcDqKRy2aNoS4qDAe/shaEb2VFQhjumF/aRVrc49y87lDCA4KzK6tHekbFsx3LhzGmn3lbC447nQc4wArEMZ0w9K1+YQFB3GTH04p6gm3Tk9jQESonYvopaxAGNNF1fVNvLLpEJdPSGJgVOCMu3Q2IsND+KcLh/HxnjJrRfRCViCM6aLXNh+iur7Jb6cU9ZQ7z0snNjKMh97f63QU42NWIIzpAlXl+bX5jE3ux+QhMU7H8arI8BC+N3M4a/aVsy7XrovoTaxAGNMF2QePsedIFbcH8LhLZ+PW6WkMig7noff22tXVvYg3pxx9WkRKRWRHm2W/EpFDIrLFdVvQwb7zRGSPiOwXkQe9ldGYrlq6Np/+fUO5amLvmH2tT2gw980awfq8Y6zZV+50HOMj3mxBPAPMc7P8f1R1kuu2qv1KEQkGHgXmA2OARSIyxos5jTkrhyvreGfnYW7ISqFvWLDTcXzmhqmpDI7pyx/e22OtiF7CawVCVVcDXbkEcxqwX1VzVbUBeAFY6NFwxnTD8vUFtKj2+JPT7YWHBHP/7Ay2FlXafBG9hBPnIO4VkW2uQ1DuZlUZDBS2eV7kWuaWiCwWkRwRySkrs+GJjXc1NLWwYn0BM0fGkzawZ4y7dDaunTyY9IER/OG9PTZ3dS/g6wLxGDAcmASUAH9ws427M34d/iSq6hJVzVLVrPj4eI+ENKYj7+w8TFlVPbfPSHc6iiNCgoP4wZyRfHm4ilU7SpyOY7zMpwVCVY+oarOqtgB/ofVwUntFQNvLUlOAYl/kM+ZMlq7NY0hsBBeP7L1fRq6YkMzIhCgeen8vTc0tTscxXuTTAiEiSW2eXgPscLPZBiBDRIaKSBhwE7DSF/mMOZ3dJSfYkHec26anEdTDxl06G8FBwg/njCS3rIY3tth3t57Mm91cVwBrgUwRKRKRbwO/FZHtIrINuAT4gWvbZBFZBaCqTcC9wLvAbuAlVd3prZzGdNZza/MJDwni+qwUp6M47rKxiYxN7scfP9xLo7UieiyvzY2oqovcLH6qg22LgQVtnq8CvtEF1hinVJ5s5PXNh1g4KZmYiDCn4zhORPjx3Ez+4ZkNvJxTxM3nDnE6kvECu5LamE7428YiTjY299qT0+7MzIxn8pAYHv5oH3WNzU7HMV5gBcKYM2hpUZ5fl8/kITGMG9zf6Th+41QroqSyjhXrC5yOY7zACoQxZ7BmfzkHy2us9eDGeSPimDFsII9+fIDahian4xgPswJhzBksXZtHXFQY88cnOh3FL/1o7kjKq+t5bm2+01GMh1mBMOY0Co/V8uGXpdw0dQjhIb1n3KWzkZUey8zMeB7/9ABVdY1OxzEeZAXCmNNYll2AgPXSOYMfzcmkoraRpz/LczqK8SArEMZ0oK6xmRc3FDB3TCLJMX2djuPXxqf057KxCTy5JpeK2gan4xgPsQJhTAfe3FbC8dpGbp/Ru0Zt7aofzBlJdUMTS1bnOh3FeIgVCGM6sHRtHiMGRTFj+ECnowSEUYn9uHJCMn/9PI/y6nqn4xgPsAJhjBtbCivYWlTZa6YU9ZQHLs2gvqmZxz454HQU4wFWIIxx47m1eUSGBXPNOb1jSlFPGRYfxbcmp7B0XT6lJ+qcjmO6yQqEMe0cq2ngzW0lXDs5heg+oU7HCTj3zhpBU3MLT3+e53QU001WIIxp58UNhTQ0tdjJ6S5KGxjJ/PFJLFuXzwm7LiKgWYEwpo1m17hLM4YNJCMh2uk4Aeuui4ZTVd/EimwboymQWYEwpo2PvizlUMVJaz100/iU/pw/YiBPfXaQ+iYb6TVQWYEwpo3n1uaR1L8Pc8YkOB0l4N118XBKq+p5Y7PNOheorEAY45JbVs2afeXcPG0IIcH2q9FdF4yIY0xSPx5ffYCWFnU6jukCb045+rSIlIrIjjbLficiX4rINhF5TURiOtg3zzU16RYRyfFWRmPaWroun9Bg4aZpNu6SJ4gI3714GLllNXy8p9TpOKYLvPk16RlgXrtl7wPjVHUCsBf459Psf4mqTlLVLC/lM+YrtQ1N/G1jEfPHJREfHe50nB5jwfgkEvqF88wXeU5HMV3gtQKhqquBY+2Wvaeqp2YVWQfY7O/GL7y+uZiquiY7Oe1hocFB3HJuGmv2lXOgrNrpOOYsOXmg9R+BtztYp8B7IrJRRBaf7kVEZLGI5IhITllZmcdDmp5PVXlubR6jk/oxJW2A03F6nEXThhAWHMRSm1Ao4DhSIETk50ATsKyDTc5X1cnAfOAeEbmoo9dS1SWqmqWqWfHx8V5Ia3q6nPzjfHm4ysZd8pL46HAun5DE3zYWUV1v05IGEp8XCBG5A7gCuEVV3XZtUNVi130p8BowzXcJTW/z3Np8ovuEsHBSstNReqw7zkunur6JVzYWOR3FnIVOFQgReUVELheRbhUUEZkH/Ay4SlVrO9gmUkSiTz0G5gI73G1rTHeVVtXxzo4Srp+SSkRYiNNxeqxJqTFMTOnPs2vzrMtrAOnsH/zHgJuBfSLyGxEZdaYdRGQFsBbIFJEiEfk28AgQDbzv6sL6uGvbZBFZ5do1AfhMRLYC64G3VPWds/tnGdM5L6wvpLFZuc1OTnvdHeelk1tWwxcHjjodxXRSp74yqeoHwAci0h9YROsf+ELgL8DzqvqNEblUdZGbl3qqg9cvBha4HucCEzsX35iua2puYXl2ARdmxDE0LtLpOD3egvFJ/Pvfd/HChgIuyIhzOo7phE4fMhKRgcCdwD8Bm4E/AZNpvbbBmIDz/q4jHD5Rx+0z0p2O0iv0CW2dX+O9nUc4XmPzVgeCzp6DeBVYA0QAV6rqVar6oqreB0R5M6Ax3vLc2nwGx/Rl1qhBTkfpNW6cmkpDcwuvbT7kdBTTCZ1tQTypqmNU9f9X1RIAEQkHsCudTSDad6SKtblHuWX6EIKDrGurr4xO6sfElP68uKGQDjoxGj/S2QLxn26WrfVkEGN8aem6fMKCg7gxK9XpKL3OjVOHsOdIFVuLKp2OYs7gtAVCRBJFZArQV0TOEZHJrttMWg83GRNwquubeHXTIa6YmMTAKBt3ydeunJhE39BgXtxgkwn5uzP1YrqM1hPTKcBDbZZXAf/ipUzGeNVrm1qv6LWT086I7hPK5ROSWLmlmF9cPobIcLv+xF+dtgWhqs+q6iXAnap6SZvbVar6qo8yGuMxreMu5TMhpT+TUmOcjtNr3Tg1lZqGZlZtL3E6ijmN05ZuEblVVZ8H0kXkh+3Xq+pDbnYzxm+tzT3KvtJqfnfdBKej9GpZaQMYEhvBG1uKud7OA/mtM52kPnX1UBStV0C3vxkTUJauzScmIpQrJ9q4S04SEa4+ZzCfHyjnyIk6p+OYDpy2BaGqT7ju/903cYzxnpLKk7y36wj/dMFQ+oQGOx2n17t6UjJ//nAfK7cU8x2nwxi3Onuh3G9FpJ+IhIrIhyJSLiK3ejucMZ60Yn0hLarcOt3GXfIHw+KjmJgaYxfN+bHOXgcxV1VP0DpMdxEwEviJ11IZ42FNzS28uKGAi0fGkxprPbT9xTWTktlVcoLahmanoxg3OlsgQl33C4AVqnrsdBsb428+/LKUIyfqueVcaz34kysnJhMcJJRX1zsdxbjR2QLxdxH5EsgCPhSReMDOLJmAsSy7gMR+fbgk02Yd9CcDo8K5eGQ85dX12MAb/qdTBUJVHwRmAFmuob1rgIXeDGaMpxQcrWXNvjJumpZKSLCT07Abd64+ZzANTS2cOPmNWQOMw87mEsbRtF4P0Xaf5zycxxiPW7GhAKH14izjf+aMTmB7kHC0poH+TocxX9PZXkxLgd8DFwBTXbfTjuIqIk+LSKmI7GizLFZE3heRfa77AR3sO09E9ojIfhF5sNP/GmPaaWhq4eWcQmaNSiCpf1+n4xg3+oYFMyAijGM1DTQ1tzgdx7TR2fZ2FnC+qn5PVe9z3b5/hn2eAea1W/Yg8KGqZgAfup5/jYgEA48C84ExwCIRGdPJnMZ8zfu7jlBe3cAt04c4HcWcRmxkGE3NLaw/aP1f/ElnC8QOIPFsXlhVVwPt/7cXAs+6Hj8LXO1m12nAflXNVdUG4AXsfIfpomXZrZMCXZRhJ6f9WUxEKEFBwps2NpNf6WyBiAN2ici7IrLy1K0L75dwasIh1727qbwGA4Vtnhe5lrklIotFJEdEcsrKyroQyfRUB8tr+OLAURZNS7VJgfxcsAgDIsJ4d8dhO8zkRzp7kvpX3gzRjrvf5A57wKnqEmAJQFZWlvWUM19Zsb6AkCDhBhsMLiAMjAzjaE0D2QePcf6IOKfjGDrfzfVTIA8IdT3eAGzqwvsdEZEkANd9qZttioC2v9EpQHEX3sv0YnWNzbycU8icMQkM6tfH6TimE2IiQokIC+bNbXaYyV90thfTd4C/AU+4Fg0GXu/C+60E7nA9vgN4w802G4AMERkqImHATa79jOm0d3ce5nhtIzefayenA0WQCLNHJ/DuTjvM5C86ew7iHuB84ASAqu7D/fmDr4jIClrnrc4UkSIR+TbwG2COiOwD5rieIyLJIrLK9dpNwL3Au8Bu4CVV3Xm2/zDTuy3LLiBtYATnD7dDFYHk8vFJHKtpYF2u9WbyB509B1Gvqg0iracHXBfLnfZ4v6ou6mDVbDfbFtM6ztOp56uAVZ3MZszX7DtSxfqDx3hw/iiC7OR0QJmZGU9kWDBvbS/mggwr7k7rbAviUxH5F6CviMwBXgb+7r1YxnTd8vUFhAYL101JcTqKOUt9QoOZPTqBd6w3k1/obIF4ECgDtgPfpfXb/S+8FcqYrqprbOaVjUXMG5dEXFS403FMFywYn8Tx2kbW5h51Okqv16lDTKraIiKvA6+rql1sYPzWm9tKOFHXxM3T7OR0oDp1mGnV9hIutAscHXXaFoS0+pWIlANfAntEpExE/tU38Yw5O8uz8xkWH8n0YbFORzFdZIeZ/MeZDjE9QGvvpamqOlBVY4FzgfNF5AfeDmfM2dhdcoJNBRXcPG0IpzpUmMC0YHwix2sbybaxmRx1pgJxO7BIVQ+eWqCqucCtrnXG+I3l2QWEhQTZyeke4OKRg+gbGszbO+yiOSedqUCEqmp5+4Wu8xChbrY3xhE19U28tvkQV4xPIiYizOk4ppv6hgVzyah43t15hOYWG0HHKWcqEA1dXGeMT/19azHV9U125XQPMm9cEmVV9WzMP+50lF7rTL2YJorICTfLBbABbozfWL6+gJEJUUxJczsHlQlAs0YNIiwkiLd3lDBtqHU6cMJpWxCqGqyq/dzcolXVDjEZv7C9qJJtRZXccm6anZzuQaLCQ7goI453dxxG1Q4zOcFmcDcBb/n6fPqEBnH1OR1OG2IC1LxxSRRX1rG1qNLpKL2SFQgT0KrqGnljSzFXTkimf19r1PY0c0YnEBIk1pvJIVYgTEB7Y0sxtQ3NdnK6h+ofEcqM4QN5xw4zOcIKhAlYqsqy7ALGJvdjUmqM03GMl8wfl0T+0Vp2l1Q5HaXXsQJhAtbmwgp2l5ywk9M93NyxCQQJvGOHmXzOCoQJWMvWFRAVHsJVk5KdjmK8KC4qnGlDY3l7x2Gno/Q6ViBMQKqobeDNbcVcfU4yUeGdnffKBKr545LYV1rN/lI7zORLPi8QIpIpIlva3E6IyAPttpkpIpVttrHRY83XvLLpEPVNLdw8Lc3pKMYHLhubCMDb260V4Us+/+qlqnuASQAiEgwcAl5zs+kaVb3Ch9FMgGg9OZ3P5CExjEnu53Qc4wOJ/fsweUgMb+84zH2zM5yO02s4fYhpNnBAVfMdzmECyLrcY+SW1XDLudZ66E3mj0tiV8kJCo7WOh2l13C6QNwErOhg3QwR2Soib4vI2I5eQEQWi0iOiOSUldlkd73Bsux8+vcN5fIJSU5HMT40b5zrMJP1ZvIZxwqEiIQBVwEvu1m9CUhT1YnAw8DrHb2Oqi5R1SxVzYqPt+kJe7qyqnre3XmY66ak0Cc02Ok4xodSYyMYN7if9WbyISdbEPOBTap6pP0KVT2hqtWux6uAUBGJ83VA439e3lhIY7PaldO91PxxSWwprKCk8qTTUXoFJwvEIjo4vCQiieK68klEptGa86gPsxk/1NKiLM8uYMawgQyPj3I6jnHAqcNM71grwiccKRAiEgHMAV5ts+wuEbnL9fQ6YIeIbAX+DNykNhBLr7d6XxlFx09yy3RrPfRWw+OjGJkQZYeZfMSRK4xUtRYY2G7Z420ePwI84utcxr8tyy4gLiqMuWMSnY5iHDR/XBJ//mgfZVX1xEeHOx2nR3O6F5MxnVJSeZIPdx/hhqxUwkLsx7Y3mz8+EVV4b5e1IrzNftNMQFiRXYACi6bZ4aXeLjMhmqFxkXZVtQ9YgTB+r76pmeXrC5iVOYjU2Ain4xiHiQjzxiWyNvcox2sanI7To1mBMH7vrW0llFc3cOf56U5HMX5i/rhEmluU93d/o5e88SArEMavqSrPfJHH8PhILhhhl8KYVuMH92dwTF/r7uplViCMX9tcWMG2okruPC/dJgUyXzl1mOmzfeVU1TU6HafHsgJh/Nozn+cRHR7CtZNTnI5i/Mz8cYk0NLfw0ZelTkfpsaxAGL915EQdq7aXcF1WCpE2KZBpZ/KQAQyKDrfeTF5kBcL4rWXZBTSrcseMdKejGD8UFCRcNjaRT/aWUtvQ5HScHskKhPFL9U3NLM8uYObIeNLjIp2OY/zU/PGJ1DW28OkeG+rfG6xAGL+0ansJ5dX13Hn+UKejGD82LT2W2Mgw3tpuc0R4gxUI45ee+SKfYXGRXGhdW81phAQHMX9cIh/sPkJNvR1m8jQrEMbv5OQdY2thBXecl05QkHVtNad39TmDqWtssbGZvMAKhPE7T6zOJSYilOuzrGurObMpQwYwOKYvr28udjpKj2MFwviVA2XVfLD7CLdNTyMizLq2mjMLChKumpTMZ/vLKa+udzpOj2IFwviVJ9fkEhocxO3WtdWchasnDaa5RXlrm52s9iSnZpTLE5HtIrJFRHLcrBcR+bOI7BeRbSIy2YmcxrfKqup5ZdMhvjU5xSaCMWclMzGaUYnRvLHlkNNRehQnWxCXqOokVc1ys24+kOG6LQYe82ky44hnv8ijsbmF71xoXVvN2Vs4aTCbCiooOFrrdJQew18PMS0EntNW64AYEUlyOpTxnpr6Jpauy2fO6ASGxUc5HccEoCsntv6JWLnVWhGe4lSBUOA9EdkoIovdrB8MFLZ5XuRaZnqo59flU3mykbtnDnc6iglQKQMimDY0llc3HUJVnY7TIzhVIM5X1cm0Hkq6R0QuarfeXed3t//jIrJYRHJEJKeszC63D0QnG5pZsjqXCzPiOGfIAKfjmAB2/ZQUcstryMk/7nSUHsGRAqGqxa77UuA1YFq7TYqA1DbPUwC3nZxVdYmqZqlqVnx8vDfiGi9blp3P0ZoGvj87w+koJsAtGJ9EZFgwL20oPPPG5ox8XiBEJFJEok89BuYCO9ptthK43dWbaTpQqarWf60Hqmts5onVucwYNpCp6bFOxzEBLjI8hCsmJPPW9hKqbeiNbnOiBZEAfCYiW4H1wFuq+o6I3CUid7m2WQXkAvuBvwDfcyCn8YEXNxRSVlXPfbNHOB3F9BA3TE2htqGZVXZNRLf5/FJVVc0FJrpZ/nibxwrc48tcxvfqm5p5/NMDTE0fwIxhA52OY3qIyUMGMCw+khdzCrlhauqZdzAd8tdurqYXeH5dASWVddw/e6TNN208RkS4MSuVjfnH2V9a7XScgGYFwjjiRF0jj3y0j/NHDOSCDBvS23jWNZMHExwkvLzRTlZ3hxUI44i/rM7leG0jP5s3yukopgcaFN2HWaMG8becIuoam52OE7CsQBifK62q48k1B7liQhITUmKcjmN6qNtnpHG0psEG8OsGKxDG5/784T4am1v48dxMp6OYHuyCEXEMj4/k2bV5dmV1F1mBMD51oKyaF9YXsmjaENLjIp2OY3owEeGO89LZVlTJ5sIKp+MEJCsQxmdUlV+t3EnfsGC7atr4xLWTU4gKD+HZL/KcjhKQrEAYn3l7x2HW7Cvnx3Mzbb4H4xNR4SFcNyWFVdtLKK2qczpOwLECYXyitqGJX7+5i9FJ/bjl3CFOxzG9yO0z0mhsVpZnFzgdJeBYgTA+8fBH+ymprOPXC8cSEmw/dsZ3hsVHMTMznufXFViX17Nkv6nG6/YdqeLJNblcNyWFLBuQzzjguxcNp7y6npdy7MK5s2EFwnhVY3MLP3xpK9F9Qnlwvl0UZ5wxfVgsU9IG8MSnuTQ2tzgdJ2BYgTBe9chH+9l+qJL/unoccVF2Yto4Q0S495IRHKo4yWubbUrSzrICYbxmW1EFj3y8n2vOGcz88TaluHHWzMx4xib347FPDtDcYhfOdYYVCOMVdY3N/PClrcRHhfOrq8Y6HceYr1oRB8trWLXdht/oDCsQxuNUlV++voP9pdX89roJ9O8b6nQkYwC4bGwiIwZF8chH+60V0QlWIIzHPZ9dwMsbi/j+rBFcNNLmCTf+IyhIuH92BnuOVPHqpiKn4/g9J+akThWRj0Vkt4jsFJH73WwzU0QqRWSL6/avvs5pumZD3jH+feVOZo8axAOXjnQ6jjHfcMWEJCalxvD79/ZwssGuizgdJ1oQTcCPVHU0MB24R0TGuNlujapOct3+w7cRTVeUVJ7k7uc3kRobwUM3TiIoyGaJM/5HRPj55aM5cqKeJ9fkOh3Hr/m8QKhqiapucj2uAnYDg32dw3hWeXU9tzyZTV1jM0tum2LnHYxfm5oey2VjE3j80wOUVdU7HcdvOXoOQkTSgXOAbDerZ4jIVhF5W0Q67AYjIotFJEdEcsrKyrwV1ZxGZW0jtz21nuKKk/z1H6aSkRDtdCRjzuhn80ZR39TC/3yw1+kofsuxAiEiUcArwAOqeqLd6k1AmqpOBB4GXu/odVR1iapmqWpWfLydEPW16vom7vjreg6UVvOX27OYakNpmAAxLD6KW6en8cL6ArbafBFuOVIgRCSU1uKwTFVfbb9eVU+oarXr8SogVERsZns/c7iyjhseX8v2Q5U8cvM5XJhhBdoElh/OHUl8dDg/e2UbDU02BEd7TvRiEuApYLeqPtTBNomu7RCRabTmPOq7lOZMdhWf4OpHPyf/aA1P3ZHF3LGJTkcy5qz16xPKf149ni8PV/HEpwecjuN3Qhx4z/OB24DtIrLFtexfgCEAqvo4cB1wt4g0ASeBm9QmlfUbq7aX8JOXt9Kvbygv33UeY5L7OR3JmC6bMyaBKyYk8fBH+5k/PpERg+wc2ik+LxCq+hlw2v6PqvoI8IhvEpnOqjzZyK9W7uS1zYeYmBrDktumkNCvj9OxjOm2X101ls/2l/PTv23jpe/OsDlLXOxTMGekqry38zDz/rialVuLeeDSDP521wwrDqbHiIsK59+vGsumggrr1dSGE4eYTADZmH+c37y9mw15xxkxKIpXb53CxNQYp2MZ43ELJw1mXe5RHv34AFPSBjBrVILTkRxnBcJ8Q0uL8uneMp75Io9P95YRHx3Of10zjhuzUq3pbXq0f7tyLFsLK/nBi1t5874LSI2NcDqSo6xAmK8UHqvlzW0lvLihgLyjtQyKDucnl2Vy53npRIbbj4rp+fqEBvPYrZO54uHPuGf5Jl5cPIO+YcFOx3KM/db3Yi0tyu7DJ1izr5x3dhxmi+tioay0AfxwbibzxiYSFmItBtO7pA2M5A/XT+S7z2/k3uWbePy2KYT20pazFYhepqyqnjX7ylizr5w1+8opr24dh2Zscj9+Nm8UV0xI6vXNamPmjk3k1wvH8YvXd/CzV7bx++sm9srBJ61A9HB1jc2sP3iMz/a3FoTdJa2jmsRGhnFhRhwXZsRzYUac9Ugypp1bp6dxvKaBP7y/lwERYfzi8tG4rt/tNaxA9DCqyq6SE6zeW85n+8vYkHechqYWQoOFKWkD+MllmVyU0To3b2/8RmTM2bh31giO1Tbw1GcHaWxu4d+uHEtwL/q9sQLRAzQ2t5Cde4z3dx3mg92lHKo4CUBmQjS3TU/jgow4zh0aS0SY/XcbczZEhF9ePoawkCCe+DSXsqp6/ufGSfQJ7R0nru0vRoBqam7hiwNHeWNLMe/tOkxVXRN9QoO4YEQ898/OYGZmPIPssJEx3RYUJPzz/NEMiu7Dr9/cxdGa9Tx2y2QGRoU7Hc3rrEAEEFVlS2EFb2wp5s1tJZRX1xMdHsLcsYlcNjaBCzPie3WXPGO86dsXDCU+Opwfv7yV+X9awx9vnMR5I3r2INNWIALA/tJqVm45xBtbi8k/WktYSBCzRw1i4aRkZmYO6jXNXWOcdtXEZDIGRXHv8k3c8lQ235s5nPtnj+yx3cGtQPipQxUneWtbMSu3FrPj0AmCBM4bHsc9l4zgsrGJNqWnMQ4ZndSPv993Ab9auZNHPz7A2zsO829XjuXikT1vPhQrEH6ktKqOt7cf5u9bi8nJPw7AhJT+/PKKMVw5IcnOKRjjJyLCQvjtdROZPz6J//j7Lu54ej2Xjk7gx5eNZFRizxn+3gqEw4orTvLxnlJWbS9h7YGjtCiMSozmJ5dlcvn4JNLjIp2OaIzpwCWZgzhv+ECe/iyPRz7ax7w/HmHWqEHcPXM4WWkDAv66CSsQPtbY3MLWwgo++rKUj74s5cvDVQAMjYvk3ktGcMXEZEYm2IQlxgSK8JBg7p45nEXTUnlubT7PfJHH9Y+vZWRCFNdOTuHqSYNJ7B+YrX/pSRO1ZWVlaU5OjtMxvqa6voktBRVsyDvGhrxjbC6o4GRjM8FBQlbaAGaNGsSsUYMYMSgq4L9tGNNlM2e23n/yiZMpPOJkQzOvbi7i1U2H2Jh/HBGYmBLDxSPjuTgznvGD+/vV2E4islFVs9yuc6JAiMg84E9AMPCkqv6m3XpxrV8A1AJ3quqmM72uUwVCVTlW00BxRR0Hj9aw5/AJ9hyuZu+RKgqO1QIQJDAqsR/ThsYyNT2WC0bE0T/CTjQbA/SoAtHWwfIaVm4p5pO9pWwprEAV+oQGMS65PxNTY8hMiCY9LpL0uAjio8Id+ZJ4ugLh80NMIhIMPArMAYqADSKyUlV3tdlsPpDhup0LPOa694rq+ibqG5upb2px3Zqpb/y/xycbmqk82UjlyUYqahupONlARW0jx2sbKKmso7jiJHWNLV+9XnCQMCwukvEp/bluSgoTU2M4Z0gM/fpYQTCmNxkaF8n9l2Zw/6UZHK9p4PMD5WwuqGBrYQXPr8unvun//m5EhYeQGhtBfHQ4cZFhDIwKIy4qnP59Q+kbFkxkWAgR4cFEhIUQGRZMn9BgwkKCCA0OIiwkiCgvDMnvxDmIacB+Vc0FEJEXgIVA2wKxEHhOW5s360QkRkSSVLXEG4Gm/Pr9r/1HnU6QQP++ocREhNG/byijEqOZlTmIwQP6khzTlyGxEQyLjyQ8xK5NMMb8nwGRYVwxIZkrJiQDraMhHKo4Sd7RWvLKazhYXkPhsVrKaxo4UFpNeXV9p/8uxUWFkfOLOR7P7ESBGAwUtnlexDdbB+62GQx8o0CIyGJgsetptYjs8VzUTokDyn38nl0VSFnB8nqb/+U9/SEW/8vbMZ9mzQfkl13ePa2jFU4UCHc/Ae1PhHRmm9aFqkuAJd0N1VUiktPR8Tt/E0hZwfJ6m+X1nkDKejpOnEovAlLbPE8BiruwjTHGGC9yokBsADJEZKiIhAE3ASvbbbMSuF1aTQcqvXX+wRhjjHs+P8Skqk0ici/wLq3dXJ9W1Z0icpdr/ePAKlq7uO6ntZvrP/g651lw7PBWFwRSVrC83mZ5vSeQsnaoR10oZ4wxxnP853I+Y4wxfsUKhDHGGLesQJyBiMSKyPsiss91P6CD7eaJyB4R2S8iD7ZZPklE1onIFhHJEZFp/pzXte4+17qdIvJbf8/rWv9jEVER8eoUXx74efidiHwpIttE5DURifFCxjN9ViIif3at3yYikzu7rzd0Na+IpIrIxyKy2/Wzer8/522zPlhENovIm77I2y2qarfT3IDfAg+6Hj8I/LebbYKBA8AwIAzYCoxxrXsPmO96vAD4xM/zXgJ8AIS7ng/y57yu9am0dnrIB+L8OS8wFwhxPf5vd/t3M99pP6s2P4dv03q90XQgu7P7euHz7E7eJGCy63E0sNef87ZZ/0NgOfCmN7N64mYtiDNbCDzrevwscLWbbb4aPkRVG4BTw4dA6wV+p2YQ6Y/3r+fobt67gd+oaj2AqpZ6N2638wL8D/BTOriY0sO6lVdV31PVJtd262i9xseTzvRZQZuhbFR1HRAjIkmd3NfTupxXVUvUNYinqlYBu2kdccEv8wKISApwOfCkl3N6hBWIM0tQ1zUYrvtBbrbpaGgQgAeA34lIIfB74J+9FxXoft6RwIUiki0in4rIVK+m7WZeEbkKOKSqW72c85Tufr5t/SOt3zQ9qTPv3dE2nc3tSd3J+xURSQfOAbI9H/Hsspxhmz/S+mWmc4MsOcwmDAJE5AMg0c2qn3f2JdwsO/Vt9m7gB6r6iojcADwFXHr2Kdu8mXfzhgADaG0aTwVeEpFh6mobd4W38opIhOs15nY1m9s38+7ne+o9fg40AcvOLl333/s023R6iBsP6vbQOyISBbwCPKCqJzyYzZ0u5xWRK4BSVd0oIjM9HcwbrEAAqtrhH2wROXKqOetqJro75HK6oUHuAE6dPHsZDzQtvZy3CHjVVRDWi0gLrQOPlflh3uHAUGCrtA7ylgJsEpFpqnrYD/Oeeo07gCuA2d0pvB3ozlA2YZ3Y19O6NfSOiITSWhyWqeqrXsx5xiyd2OY64CoRWQD0AfqJyPOqeqsX83aP0ydB/P0G/I6vn5T8rZttQoBcWv9YnTpxNda1bjcw0/V4NrDRz/PeBfyH6/FIWpvK4q95222Xh/dPUnf3851H69D28V7Kd8bPitZj4G1Poq4/m8/Zj/IK8BzwR29m9FTedtvMJABOUjsewN9vwEDgQ2Cf6z7WtTwZWNVmuwW09qI4APy8zfILgI2uH6RsYIqf5w0Dngd2AJuAWf6ct91r5eH9AtHdz3c/rUV3i+v2uBcyfuO9aS38d7keC62Tdh0AtgNZZ/M5+0te1++WAtvafJ4L/DVvu9eYSQAUCBtqwxhjjFvWi8kYY4xbViCMMca4ZQXCGGOMW1YgjDHGuGUFwhhjjFtWIIwxxrhlBcIYY4xb/w8RDiZwMmnjLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.kdeplot(randomscorediffs)\n",
    "plt.axvline(chronscorediff, 0, 30, color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "external-cliff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(randomscorediffs > chronscorediff) / len(randomscorediffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-wiring",
   "metadata": {},
   "source": [
    "A difference of that size could well happen by chance, (p > .05) so we cannot be very confident that gender roles became less predictable at the end of the 20c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-tournament",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
