{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "favorite-execution",
   "metadata": {},
   "source": [
    "# Predictive modeling\n",
    "\n",
    "Let's start with the Crowdflower Airline Sentiment Twitter dataset. \n",
    "\n",
    "    A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\").\n",
    "    \n",
    "This dataset was produced by human categorization. But if you were working for an airline, you can easily imagine that you might want to assess customer sentiment (and reasons for negative sentiment) week by week without manually categorizing thousands of tweets. To do that, you might need to train some kind of predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "significant-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from pathlib import Path\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-velvet",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "Let's start by loading the data and doing some exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incorporate-killing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14640, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment negativereason  retweet_count         airline  \\\n",
       "0           neutral            NaN              0  Virgin America   \n",
       "1          positive            NaN              0  Virgin America   \n",
       "2           neutral            NaN              0  Virgin America   \n",
       "3          negative     Bad Flight              0  Virgin America   \n",
       "4          negative     Can't Tell              0  Virgin America   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetpath = Path('../../data/tweets/flight_sentiment.tsv')\n",
    "\n",
    "tweets = pd.read_csv(tweetpath, sep ='\\t')\n",
    "\n",
    "print(tweets.shape)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-database",
   "metadata": {},
   "source": [
    "#### Exploratory data analysis\n",
    "\n",
    "It's always a good idea to inspect the data before modeling it.\n",
    "\n",
    "1. Find out what the top three reasons for unhappiness are. \n",
    "\n",
    "2. Visualize the distribution of positive, neutral, and negative ```airline_sentiment``` as a bar graph.\n",
    "\n",
    "3. Examine the full texts of 5 tweets in the \"Bad Flight\" category, to see what that actually means.\n",
    "\n",
    "To make full texts a little easier to inspect I'm going to start by telling Pandas to display the full column width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compressed-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incident-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer Service Issue         2910\n",
       "Late Flight                    1665\n",
       "Can't Tell                     1190\n",
       "Cancelled Flight                847\n",
       "Lost Luggage                    724\n",
       "Bad Flight                      580\n",
       "Flight Booking Problems         529\n",
       "Flight Attendant Complaints     481\n",
       "longlines                       178\n",
       "Damaged Luggage                  74\n",
       "Name: negativereason, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['negativereason'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alone-addition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets['airline_sentiment'].value_counts().plot.bar(color = ['blue', 'green', 'red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regional-number",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last week and couldn't fully sit in my seat due to two large gentleman on either side of me. HELP!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica amazing to me that we can't get any cold air from the vents. #VX358 #noair #worstflightever #roasted #SFOtoBOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@virginamerica why don't any of the pairings include red wine?! Only white is offered :( #redwineisbetter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica seats in Row 8 don't recline should mention that on your website #soreback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14484</th>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir after all, the plane didn’t land in identical or worse) conditions at GRK according to METARs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14550</th>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir and how is this not a mechanical issue? All evidence points to the idea that it’s the ILS at CLL at fault, not the weather.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14555</th>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir fix the engine of flight AA3031so I don't spend all night in your airport so I can fly home tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14618</th>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir 3078 is overweight so you pull 2 dozen passengers off? Why not luggage? Seriously?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14631</th>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir thx for nothing on getting us out of the country and back to US. Broken plane? Come on. Get another one.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment negativereason  retweet_count         airline  \\\n",
       "3              negative     Bad Flight              0  Virgin America   \n",
       "17             negative     Bad Flight              0  Virgin America   \n",
       "28             negative     Bad Flight              0  Virgin America   \n",
       "162            negative     Bad Flight              0  Virgin America   \n",
       "209            negative     Bad Flight              0  Virgin America   \n",
       "...                 ...            ...            ...             ...   \n",
       "14484          negative     Bad Flight              0        American   \n",
       "14550          negative     Bad Flight              0        American   \n",
       "14555          negative     Bad Flight              0        American   \n",
       "14618          negative     Bad Flight              0        American   \n",
       "14631          negative     Bad Flight              0        American   \n",
       "\n",
       "                                                                                                                                            text  \n",
       "3                 @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse  \n",
       "17     @VirginAmerica  I flew from NYC to SFO last week and couldn't fully sit in my seat due to two large gentleman on either side of me. HELP!  \n",
       "28                 @VirginAmerica amazing to me that we can't get any cold air from the vents. #VX358 #noair #worstflightever #roasted #SFOtoBOS  \n",
       "162                                    @virginamerica why don't any of the pairings include red wine?! Only white is offered :( #redwineisbetter  \n",
       "209                                                    @VirginAmerica seats in Row 8 don't recline should mention that on your website #soreback  \n",
       "...                                                                                                                                          ...  \n",
       "14484                                @AmericanAir after all, the plane didn’t land in identical or worse) conditions at GRK according to METARs.  \n",
       "14550   @AmericanAir and how is this not a mechanical issue? All evidence points to the idea that it’s the ILS at CLL at fault, not the weather.  \n",
       "14555                          @AmericanAir fix the engine of flight AA3031so I don't spend all night in your airport so I can fly home tomorrow  \n",
       "14618                                            @AmericanAir 3078 is overweight so you pull 2 dozen passengers off? Why not luggage? Seriously?  \n",
       "14631                      @AmericanAir thx for nothing on getting us out of the country and back to US. Broken plane? Come on. Get another one.  \n",
       "\n",
       "[580 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[tweets.negativereason == 'Bad Flight', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-jurisdiction",
   "metadata": {},
   "source": [
    "### Now create a term-document matrix (wordcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "czech-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features = 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-catholic",
   "metadata": {},
   "source": [
    "I'm going to start occasionally using an alternative way to refer to Pandas columns, which is simply\n",
    "\n",
    "    ```df.columnname```\n",
    "    instead of\n",
    "    ```df['columnname']\n",
    "\n",
    "This can occasionally be confusing. If you name a column something like \"shape\" for instance, you could be in trouble! But it's a lot quicker to type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unusual-footwear",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0016</th>\n",
       "      <th>00pm</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>05am</th>\n",
       "      <th>05pm</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yuma</th>\n",
       "      <th>yup</th>\n",
       "      <th>yvr</th>\n",
       "      <th>yyz</th>\n",
       "      <th>zero</th>\n",
       "      <th>zkatcher</th>\n",
       "      <th>zone</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0016  00pm  02  03  05  05am  05pm  08  ...  yr  yrs  yuma  yup  \\\n",
       "0   0    0     0     0   0   0   0     0     0   0  ...   0    0     0    0   \n",
       "1   0    0     0     0   0   0   0     0     0   0  ...   0    0     0    0   \n",
       "2   0    0     0     0   0   0   0     0     0   0  ...   0    0     0    0   \n",
       "3   0    0     0     0   0   0   0     0     0   0  ...   0    0     0    0   \n",
       "4   0    0     0     0   0   0   0     0     0   0  ...   0    0     0    0   \n",
       "\n",
       "   yvr  yyz  zero  zkatcher  zone  zurich  \n",
       "0    0    0     0         0     0       0  \n",
       "1    0    0     0         0     0       0  \n",
       "2    0    0     0         0     0       0  \n",
       "3    0    0     0         0     0       0  \n",
       "4    0    0     0         0     0       0  \n",
       "\n",
       "[5 rows x 4000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_wordcounts = vectorizer.fit_transform(tweets.text)\n",
    "wordcounts = sparse_wordcounts.toarray()\n",
    "tweetwords = pd.DataFrame(wordcounts, columns = vectorizer.get_feature_names())\n",
    "tweetwords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-frederick",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "If we really cared about maximizing accuracy it would probably be worthwhile to think hard about the strategy we're using to count words. For instance, how will the CountVectorizer handle a hashtag like \"#soreback\"? How might we ideally want to handle it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-palmer",
   "metadata": {},
   "source": [
    "Let's use the technique we learned last time to select some of the words most likely to predict positive or negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "crazy-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = tweetwords.loc[tweets.airline_sentiment == 'negative', :].sum(axis = 'rows')\n",
    "positive_words = tweetwords.loc[tweets.airline_sentiment == 'positive', :].sum(axis = 'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accompanied-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dunnings(word, series1, series2):\n",
    "    observed = pd.DataFrame({'series1': [series1[word], sum(series1) - series1[word]],\n",
    "                          'series2': [series2[word], sum(series2) - series2[word]]},\n",
    "                        index = ['word', 'all_others'])\n",
    "    total_words = observed.to_numpy().sum()\n",
    "    observed['word_totals'] = observed.sum(axis = 1)\n",
    "    observed = observed.append(observed.sum(axis = 0).rename(index = 'group_totals'))\n",
    "    observed.iat[2,2] = 0\n",
    "    observed['word_totals'] = observed['word_totals'] / sum(observed['word_totals'])\n",
    "    observed.loc['group_totals', : ] = observed.loc['group_totals', : ] / sum(observed.loc['group_totals', : ])\n",
    "    expected = np.outer(observed['word_totals'][0:2], observed.loc['group_totals', : ][0:2])\n",
    "    expected = pd.DataFrame(expected, index = ['word', 'all_others'], columns = ['series1', 'series2'])\n",
    "    expected = expected * total_words\n",
    "    \n",
    "    G = 0\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            O = observed.iat[i, j] + .000001\n",
    "            E = expected.iat[i, j] + .000001\n",
    "            G = G + O * math.log(O / E)\n",
    "    \n",
    "    if (observed.iat[0, 0] / sum(observed.iloc[0: 2, 0])) < (observed.iat[0, 1] / sum(observed.iloc[0 : 2, 1])):\n",
    "        G = -G    # we provide a signed version of the statistic to distinguish\n",
    "                  # overrepresentation in the two categories\n",
    "    \n",
    "    return 2 * G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "amended-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "dunningslist = []\n",
    "\n",
    "for w in vectorizer.get_feature_names():\n",
    "    G = get_dunnings(w, positive_words, negative_words)\n",
    "    dunningslist.append(G)\n",
    "\n",
    "dunnings = pd.Series(dunningslist, index = vectorizer.get_feature_names())\n",
    "dunnings = dunnings.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stone-amazon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no          -165.609085\n",
       "hours       -165.077254\n",
       "hold        -154.163694\n",
       "not         -138.953626\n",
       "cancelled   -130.925833\n",
       "delayed      -86.071118\n",
       "flightled    -83.028421\n",
       "worst        -80.248818\n",
       "hour         -74.138316\n",
       "call         -73.718327\n",
       "why          -65.215920\n",
       "been         -59.384149\n",
       "is           -58.140458\n",
       "hrs          -56.984742\n",
       "usairways    -55.275240\n",
       "waiting      -53.808645\n",
       "can          -48.977909\n",
       "because      -47.704688\n",
       "told         -47.414103\n",
       "luggage      -47.414103\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunnings[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-rogers",
   "metadata": {},
   "source": [
    "No one mentions \"luggage\" or \"hours\" if they're happy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "south-composition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent          68.405151\n",
       "wonderful          68.405151\n",
       "kudos              79.253573\n",
       "rock               82.791590\n",
       "appreciate        103.413990\n",
       "good              110.310671\n",
       "http              128.769954\n",
       "co                145.210322\n",
       "much              158.874557\n",
       "virginamerica     171.634044\n",
       "best              192.788829\n",
       "amazing           218.934091\n",
       "you               238.134708\n",
       "awesome           280.567625\n",
       "love              287.073472\n",
       "southwestair      319.243684\n",
       "jetblue           431.915012\n",
       "great             553.288110\n",
       "thanks           1218.129806\n",
       "thank            1284.022918\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunnings[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-classroom",
   "metadata": {},
   "source": [
    "Let's select a list of 400 highly predictive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "raising-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremefeatures = list(dunnings.index[0:100].values) + list(dunnings.index[-100: ].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "colonial-coordination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'hours', 'hold', 'not', 'cancelled']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extremefeatures[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-assistant",
   "metadata": {},
   "source": [
    "### A first model: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-favor",
   "metadata": {},
   "source": [
    "To keep this simple to start with, let's create a dataframe with even numbers of positive and negative tweets. Let's say 200 positive ones and 200 negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "suspected-harmony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_tweets = tweetwords.loc[tweets.airline_sentiment == 'positive', :]\n",
    "negative_tweets = tweetwords.loc[tweets.airline_sentiment == 'negative', :]\n",
    "\n",
    "sample400_allwords = pd.concat([positive_tweets.iloc[0:200, : ], negative_tweets.iloc[0: 200, : ]], axis = 'rows')\n",
    "sample400_allwords.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-gravity",
   "metadata": {},
   "source": [
    "Let's also create a version of this data limited to our list of 200 highly predictive (extreme) features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "simple-trademark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample400_ext200 = sample400_allwords.loc[ : , extremefeatures]  # why does this work?\n",
    "sample400_ext200.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-burden",
   "metadata": {},
   "source": [
    "Now we need a list of true labels for the model to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "herbal-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sentiment_400 = [1] * 200 + [0] * 200\n",
    "# what will that produce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "twenty-minority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_sentiment_400[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-spice",
   "metadata": {},
   "source": [
    "Now let's train a first model. We'll use just the 200 words that Dunnings identified as extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "productive-trick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8825"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_bayes = MultinomialNB(alpha = .1)   # Alpha sets the \"smoothing.\" Notice we're not using much.\n",
    "sm_bayes.fit(sample400_ext200, true_sentiment_400)   # Here we actually fit the model\n",
    "\n",
    "sm_predictions = sm_bayes.predict(sample400_ext200)   # Now let's see what the model predicts if we give it\n",
    "sum(sm_predictions == true_sentiment_400) / len(sm_predictions)  # the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-crown",
   "metadata": {},
   "source": [
    "Not a bad prediction. But how would this model do if we gave it new data?\n",
    "\n",
    "Let's make a bigger dataset, with the next 1500 negative tweets and the next 1500 positive tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "celtic-setting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 4000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next3000 =  pd.concat([positive_tweets.iloc[200: 1700, : ], negative_tweets.iloc[200: 1700, : ]], axis = 'rows')\n",
    "true_sentiment_3000 = [1] * 1500 + [0] * 1500\n",
    "next3000.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-leeds",
   "metadata": {},
   "source": [
    "Now a version limited to 200 words that are strongly associated with positive or negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dangerous-confidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 200)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next3000_ext200 = next3000.loc[ : , extremefeatures]\n",
    "next3000_ext200.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "domestic-message",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7953333333333333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_predictions = sm_bayes.predict(next3000_ext200)\n",
    "sum(sm_predictions == true_sentiment_3000) / len(sm_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-williams",
   "metadata": {},
   "source": [
    "Oh, that's much worse. Maybe we could improve this by increasing the number of words we use to predict? Let's train on the version of our 400-tweet dataset that has all 5000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "small-yahoo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9925"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_bayes = MultinomialNB(alpha = 0.1)\n",
    "big_bayes.fit(sample400_allwords, true_sentiment_400)\n",
    "big_predictions = big_bayes.predict(sample400_allwords)\n",
    "sum(big_predictions == true_sentiment_400) / len(big_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-thought",
   "metadata": {},
   "source": [
    "Ah, yes. Including lots more words makes our model almost perfectly accurate on the 400 tweets we used to train it.\n",
    "\n",
    "Maybe that will also improve accuracy on the new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "polished-municipality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7313333333333333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_predictions = big_bayes.predict(next3000.loc[ : , : ])\n",
    "sum(big_predictions == true_sentiment_3000) / len(big_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-soviet",
   "metadata": {},
   "source": [
    "Yikes!! This is not helping.\n",
    "\n",
    "#### Discussion:\n",
    "\n",
    "What do we need to do to improve accuracy?\n",
    "\n",
    "#### Exercise:\n",
    "\n",
    "Working in small groups, construct a loop that implements the solution we've described, and finds the parameter setting that maximizes accuracy *on our large 3000-tweet dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "forty-folder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.6926666666666667\n",
      "0.1 0.7313333333333333\n",
      "1 0.759\n",
      "2 0.7573333333333333\n",
      "4 0.7503333333333333\n",
      "6 0.7376666666666667\n",
      "10 0.7216666666666667\n"
     ]
    }
   ],
   "source": [
    "for alpha in [.01, .1, 1, 2, 4, 6, 10]:\n",
    "    big_bayes = MultinomialNB(alpha = alpha)\n",
    "    big_bayes.fit(sample400_allwords, true_sentiment_400)\n",
    "    big_predictions = big_bayes.predict(next3000.loc[ : , : ])\n",
    "    print(alpha, sum(big_predictions == true_sentiment_3000) / len(big_predictions))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-stick",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "Separating test and train datasets is a strategy to avoid overfitting, and the exercise above was designed to demonstrate why overfitting is a danger.\n",
    "\n",
    "But there are several aspects of what we did above that aren't actually recommended practice.\n",
    "\n",
    "1. First, we had a small training dataset (400) and a big test set (3000). But you normally have a training dataset that is much larger than the test dataset. Ratios of 7 to 3 or 9 to 1 are common.\n",
    "\n",
    "2. It's not a good idea to do *feature selection* on the whole dataset. We selected our \"extreme 400\" features by calculating Dunning's log-likelihood on the whole corpus of tweets--but really, if we wanted to use a feature selection strategy, we should only calculate Dunning's on the *training* dataset. Otherwise we may get misleadingly high accuracy. Can you figure out why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-heater",
   "metadata": {},
   "source": [
    "### Inspect probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "appointed-combining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24716759, 0.75283241],\n",
       "       [0.66905453, 0.33094547],\n",
       "       [0.49552751, 0.50447249],\n",
       "       [0.08209022, 0.91790978],\n",
       "       [0.1042556 , 0.8957444 ],\n",
       "       [0.48221875, 0.51778125],\n",
       "       [0.01739582, 0.98260418],\n",
       "       [0.05254278, 0.94745722],\n",
       "       [0.24080718, 0.75919282],\n",
       "       [0.32471968, 0.67528032]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_probabilities = sm_bayes.predict_proba(sample400_ext200)\n",
    "sm_predictions = sm_bayes.predict(sample400_ext200)\n",
    "sm_probabilities[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "crude-france",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7528324064379827,\n",
       " 0.3309454659730444,\n",
       " 0.5044724868392012,\n",
       " 0.9179097801485073,\n",
       " 0.8957443989764363,\n",
       " 0.5177812508721986,\n",
       " 0.9826041794136698,\n",
       " 0.9474572248679309,\n",
       " 0.7591928179406537,\n",
       " 0.6752803203150606]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_probabilities = [x[1] for x in sm_probabilities]\n",
    "sm_probabilities[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "downtown-kruger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aging-simulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fed99b78310>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.array(true_sentiment_400) + np.random.random(size = 400)/3, np.array(sm_probabilities),\n",
    "            c = (sm_predictions == np.array(true_sentiment_400)), cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-aspect",
   "metadata": {},
   "source": [
    "## Logistic regression, and how we might really do this\n",
    "\n",
    "Naive Bayes is simple, which makes it a good example to teach first. But in real-life problems (especially if documents are reasonably long), regularized logistic regression is more commonly where a modeling process will start. There are lots of approaches more sophisticated than logistic regression, but LR makes a good \"baseline,\" and is often in practice good enough for the task.\n",
    "\n",
    "As we work through a solution here, I'm going to dispense with some of the simplifying assumptions we initially made. For instance, we constructed an imaginary world where classes of tweets were \"balanced\" (of equal size). As we know, that's not actually true in our real-world data. \n",
    "\n",
    "So let's go back to our original complete doc-term matrix, ```tweetwords```.\n",
    "\n",
    "#### preparing the data\n",
    "\n",
    "Because this matrix is based on raw word counts, it conflates word frequency with tweet length. Tweet-length might be an interesting predictive feature, but we probably don't want it mixed into all the different words. Let's factor it out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "manufactured-resource",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     35\n",
       "1     72\n",
       "2     71\n",
       "3    126\n",
       "4     55\n",
       "5    135\n",
       "6     79\n",
       "7    108\n",
       "8     47\n",
       "9     80\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetlengths = tweets['text'].str.len()\n",
    "tweetlengths[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "resident-skating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0016</th>\n",
       "      <th>00pm</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>05am</th>\n",
       "      <th>05pm</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yuma</th>\n",
       "      <th>yup</th>\n",
       "      <th>yvr</th>\n",
       "      <th>yyz</th>\n",
       "      <th>zero</th>\n",
       "      <th>zkatcher</th>\n",
       "      <th>zone</th>\n",
       "      <th>zurich</th>\n",
       "      <th>#tweetlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 4001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  0016  00pm   02   03   05  05am  05pm   08  ...  yrs  yuma  \\\n",
       "0      0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "1      0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "2      0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "3      0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "4      0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "...    ...  ...   ...   ...  ...  ...  ...   ...   ...  ...  ...  ...   ...   \n",
       "14635  0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "14636  0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "14637  0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "14638  0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "14639  0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "\n",
       "       yup  yvr  yyz  zero  zkatcher  zone  zurich  #tweetlen  \n",
       "0      0.0  0.0  0.0   0.0       0.0   0.0     0.0         35  \n",
       "1      0.0  0.0  0.0   0.0       0.0   0.0     0.0         72  \n",
       "2      0.0  0.0  0.0   0.0       0.0   0.0     0.0         71  \n",
       "3      0.0  0.0  0.0   0.0       0.0   0.0     0.0        126  \n",
       "4      0.0  0.0  0.0   0.0       0.0   0.0     0.0         55  \n",
       "...    ...  ...  ...   ...       ...   ...     ...        ...  \n",
       "14635  0.0  0.0  0.0   0.0       0.0   0.0     0.0         63  \n",
       "14636  0.0  0.0  0.0   0.0       0.0   0.0     0.0        150  \n",
       "14637  0.0  0.0  0.0   0.0       0.0   0.0     0.0         60  \n",
       "14638  0.0  0.0  0.0   0.0       0.0   0.0     0.0        135  \n",
       "14639  0.0  0.0  0.0   0.0       0.0   0.0     0.0        138  \n",
       "\n",
       "[14640 rows x 4001 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreqs = tweetwords.divide(tweetlengths, axis = 'rows')\n",
    "wordfreqs['#tweetlen'] = tweetlengths\n",
    "wordfreqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-protein",
   "metadata": {},
   "source": [
    "We're going to want to hold out a \"test\" set to finally confirm the quality of our model. This should be randomly selected from all tweets, and we don't know the current sequence is random. So let's shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sitting-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0016</th>\n",
       "      <th>00pm</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>05am</th>\n",
       "      <th>05pm</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yuma</th>\n",
       "      <th>yup</th>\n",
       "      <th>yvr</th>\n",
       "      <th>yyz</th>\n",
       "      <th>zero</th>\n",
       "      <th>zkatcher</th>\n",
       "      <th>zone</th>\n",
       "      <th>zurich</th>\n",
       "      <th>#tweetlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10182</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  0016  00pm   02   03   05  05am  05pm   08  ...  yrs  yuma  \\\n",
       "13296  0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "778    0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "7023   0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "10182  0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "10979  0.0  0.0   0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  ...  0.0   0.0   \n",
       "\n",
       "       yup  yvr  yyz  zero  zkatcher  zone  zurich  #tweetlen  \n",
       "13296  0.0  0.0  0.0   0.0       0.0   0.0     0.0        140  \n",
       "778    0.0  0.0  0.0   0.0       0.0   0.0     0.0        144  \n",
       "7023   0.0  0.0  0.0   0.0       0.0   0.0     0.0         60  \n",
       "10182  0.0  0.0  0.0   0.0       0.0   0.0     0.0         75  \n",
       "10979  0.0  0.0  0.0   0.0       0.0   0.0     0.0        105  \n",
       "\n",
       "[5 rows x 4001 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreqs = wordfreqs.sample(frac = 1)\n",
    "wordfreqs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-engineer",
   "metadata": {},
   "source": [
    "Notice that the indexes were shuffled too. This allows us to create a reordered ```tweets``` frame in the same order. We're going to need this if we want to know the true sentiment for all those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abstract-stuart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>negative</td>\n",
       "      <td>Flight Attendant Complaints</td>\n",
       "      <td>0</td>\n",
       "      <td>American</td>\n",
       "      <td>@AmericanAir @cnnbrk she tried they are not doing anything said they would talk to stewardess about serving drunks drinks how does that help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>negative</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0</td>\n",
       "      <td>United</td>\n",
       "      <td>@united I'm constantly having challenges with upgrades &amp;amp; charges. In order to prevent DVT I have to pay an addtl $180 http://t.co/xC6jQ70r7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Delta</td>\n",
       "      <td>😂😂 RT @JetBlue: Our fleet's on fleek. http://t.co/rinzYSK6kI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10182</th>\n",
       "      <td>negative</td>\n",
       "      <td>Cancelled Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways Good grief! Flight Cancelled Flightled. Been on hold since 0400.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>negative</td>\n",
       "      <td>Late Flight</td>\n",
       "      <td>0</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>@USAirways I have been on three planes for flight 1907 and still haven't left the ground BAD SERVICE #sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment               negativereason  retweet_count  \\\n",
       "13296          negative  Flight Attendant Complaints              0   \n",
       "778            negative                   Can't Tell              0   \n",
       "7023            neutral                          NaN              0   \n",
       "10182          negative             Cancelled Flight              0   \n",
       "10979          negative                  Late Flight              0   \n",
       "\n",
       "          airline  \\\n",
       "13296    American   \n",
       "778        United   \n",
       "7023        Delta   \n",
       "10182  US Airways   \n",
       "10979  US Airways   \n",
       "\n",
       "                                                                                                                                                   text  \n",
       "13296      @AmericanAir @cnnbrk she tried they are not doing anything said they would talk to stewardess about serving drunks drinks how does that help  \n",
       "778    @united I'm constantly having challenges with upgrades &amp; charges. In order to prevent DVT I have to pay an addtl $180 http://t.co/xC6jQ70r7B  \n",
       "7023                                                                                       😂😂 RT @JetBlue: Our fleet's on fleek. http://t.co/rinzYSK6kI  \n",
       "10182                                                                       @USAirways Good grief! Flight Cancelled Flightled. Been on hold since 0400.  \n",
       "10979                                         @USAirways I have been on three planes for flight 1907 and still haven't left the ground BAD SERVICE #sad  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reorderedtweets = tweets.loc[wordfreqs.index, : ]\n",
    "reorderedtweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-projection",
   "metadata": {},
   "source": [
    "For our simplifying purposes let's get rid of 'neutral's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cloudy-delhi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11541, 4001)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreqs = wordfreqs.loc[reorderedtweets['airline_sentiment'] != 'neutral', : ]\n",
    "reorderedtweets = reorderedtweets.loc[reorderedtweets['airline_sentiment'] != 'neutral', : ]\n",
    "wordfreqs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-alexandria",
   "metadata": {},
   "source": [
    "Now let's separate the tweets into test and train sets. There's not a hard and fast rule on proportions here; it depends on how much data you have. People with tons of data may do a 90-10 split. 11,541 rows is not exactly tons and we want a good readout of final accuracy, so let's set 2000 aside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "assured-cambodia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13296    0\n",
       "778      0\n",
       "10182    0\n",
       "10979    0\n",
       "3356     0\n",
       "1086     1\n",
       "7906     0\n",
       "11056    0\n",
       "9489     0\n",
       "10107    0\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testfreqs = wordfreqs.iloc[0: 2000, : ]\n",
    "test_y = (reorderedtweets['airline_sentiment'][0: 2000] == 'positive').astype(int)  # try taking the last part out\n",
    "test_y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "requested-percentage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12704    1\n",
       "4144     0\n",
       "11729    0\n",
       "12121    0\n",
       "11676    1\n",
       "2852     0\n",
       "660      0\n",
       "7680     0\n",
       "6980     0\n",
       "9747     0\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainfreqs = wordfreqs.iloc[2000 : , : ]\n",
    "train_y = (reorderedtweets['airline_sentiment'][2000: ] == 'positive').astype(int) \n",
    "train_y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-hepatitis",
   "metadata": {},
   "source": [
    "We want regularization to spread evenly across different variables, even though some variables (like ```#tweetlen```) are numerically much bigger than others. So we typically \"scale\" our X matrices before using logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sixth-dryer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0016</th>\n",
       "      <th>00pm</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>05am</th>\n",
       "      <th>05pm</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yuma</th>\n",
       "      <th>yup</th>\n",
       "      <th>yvr</th>\n",
       "      <th>yyz</th>\n",
       "      <th>zero</th>\n",
       "      <th>zkatcher</th>\n",
       "      <th>zone</th>\n",
       "      <th>zurich</th>\n",
       "      <th>#tweetlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.030217</td>\n",
       "      <td>-0.048307</td>\n",
       "      <td>-0.010238</td>\n",
       "      <td>-0.014474</td>\n",
       "      <td>-0.01909</td>\n",
       "      <td>-0.014391</td>\n",
       "      <td>-0.024479</td>\n",
       "      <td>-0.010238</td>\n",
       "      <td>-0.017497</td>\n",
       "      <td>-0.016838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023857</td>\n",
       "      <td>-0.019246</td>\n",
       "      <td>-0.024403</td>\n",
       "      <td>-0.017481</td>\n",
       "      <td>-0.031032</td>\n",
       "      <td>-0.056441</td>\n",
       "      <td>-0.017555</td>\n",
       "      <td>-0.020057</td>\n",
       "      <td>-0.017619</td>\n",
       "      <td>-1.448856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.030217</td>\n",
       "      <td>-0.048307</td>\n",
       "      <td>-0.010238</td>\n",
       "      <td>-0.014474</td>\n",
       "      <td>-0.01909</td>\n",
       "      <td>-0.014391</td>\n",
       "      <td>-0.024479</td>\n",
       "      <td>-0.010238</td>\n",
       "      <td>-0.017497</td>\n",
       "      <td>-0.016838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023857</td>\n",
       "      <td>-0.019246</td>\n",
       "      <td>-0.024403</td>\n",
       "      <td>-0.017481</td>\n",
       "      <td>-0.031032</td>\n",
       "      <td>-0.056441</td>\n",
       "      <td>-0.017555</td>\n",
       "      <td>-0.020057</td>\n",
       "      <td>-0.017619</td>\n",
       "      <td>-0.263589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.030217</td>\n",
       "      <td>-0.048307</td>\n",
       "      <td>-0.010238</td>\n",
       "      <td>-0.014474</td>\n",
       "      <td>-0.01909</td>\n",
       "      <td>-0.014391</td>\n",
       "      <td>-0.024479</td>\n",
       "      <td>-0.010238</td>\n",
       "      <td>-0.017497</td>\n",
       "      <td>-0.016838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023857</td>\n",
       "      <td>-0.019246</td>\n",
       "      <td>-0.024403</td>\n",
       "      <td>-0.017481</td>\n",
       "      <td>-0.031032</td>\n",
       "      <td>-0.056441</td>\n",
       "      <td>-0.017555</td>\n",
       "      <td>-0.020057</td>\n",
       "      <td>-0.017619</td>\n",
       "      <td>0.921678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.030217</td>\n",
       "      <td>-0.048307</td>\n",
       "      <td>-0.010238</td>\n",
       "      <td>-0.014474</td>\n",
       "      <td>-0.01909</td>\n",
       "      <td>-0.014391</td>\n",
       "      <td>-0.024479</td>\n",
       "      <td>-0.010238</td>\n",
       "      <td>-0.017497</td>\n",
       "      <td>-0.016838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023857</td>\n",
       "      <td>-0.019246</td>\n",
       "      <td>-0.024403</td>\n",
       "      <td>-0.017481</td>\n",
       "      <td>-0.031032</td>\n",
       "      <td>-0.056441</td>\n",
       "      <td>-0.017555</td>\n",
       "      <td>-0.020057</td>\n",
       "      <td>-0.017619</td>\n",
       "      <td>0.690406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.030217</td>\n",
       "      <td>-0.048307</td>\n",
       "      <td>-0.010238</td>\n",
       "      <td>-0.014474</td>\n",
       "      <td>-0.01909</td>\n",
       "      <td>-0.014391</td>\n",
       "      <td>-0.024479</td>\n",
       "      <td>-0.010238</td>\n",
       "      <td>-0.017497</td>\n",
       "      <td>-0.016838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023857</td>\n",
       "      <td>-0.019246</td>\n",
       "      <td>-0.024403</td>\n",
       "      <td>-0.017481</td>\n",
       "      <td>-0.031032</td>\n",
       "      <td>-0.056441</td>\n",
       "      <td>-0.017555</td>\n",
       "      <td>-0.020057</td>\n",
       "      <td>-0.017619</td>\n",
       "      <td>-2.634123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000      0016      00pm       02        03        05  \\\n",
       "0 -0.030217 -0.048307 -0.010238 -0.014474 -0.01909 -0.014391 -0.024479   \n",
       "1 -0.030217 -0.048307 -0.010238 -0.014474 -0.01909 -0.014391 -0.024479   \n",
       "2 -0.030217 -0.048307 -0.010238 -0.014474 -0.01909 -0.014391 -0.024479   \n",
       "3 -0.030217 -0.048307 -0.010238 -0.014474 -0.01909 -0.014391 -0.024479   \n",
       "4 -0.030217 -0.048307 -0.010238 -0.014474 -0.01909 -0.014391 -0.024479   \n",
       "\n",
       "       05am      05pm        08  ...       yrs      yuma       yup       yvr  \\\n",
       "0 -0.010238 -0.017497 -0.016838  ... -0.023857 -0.019246 -0.024403 -0.017481   \n",
       "1 -0.010238 -0.017497 -0.016838  ... -0.023857 -0.019246 -0.024403 -0.017481   \n",
       "2 -0.010238 -0.017497 -0.016838  ... -0.023857 -0.019246 -0.024403 -0.017481   \n",
       "3 -0.010238 -0.017497 -0.016838  ... -0.023857 -0.019246 -0.024403 -0.017481   \n",
       "4 -0.010238 -0.017497 -0.016838  ... -0.023857 -0.019246 -0.024403 -0.017481   \n",
       "\n",
       "        yyz      zero  zkatcher      zone    zurich  #tweetlen  \n",
       "0 -0.031032 -0.056441 -0.017555 -0.020057 -0.017619  -1.448856  \n",
       "1 -0.031032 -0.056441 -0.017555 -0.020057 -0.017619  -0.263589  \n",
       "2 -0.031032 -0.056441 -0.017555 -0.020057 -0.017619   0.921678  \n",
       "3 -0.031032 -0.056441 -0.017555 -0.020057 -0.017619   0.690406  \n",
       "4 -0.031032 -0.056441 -0.017555 -0.020057 -0.017619  -2.634123  \n",
       "\n",
       "[5 rows x 4001 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainscaler = StandardScaler()\n",
    "trainXscaled = trainscaler.fit_transform(trainfreqs)\n",
    "trainXscaled = pd.DataFrame(trainXscaled, columns = trainfreqs.columns)\n",
    "trainXscaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "comprehensive-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "testscaler = StandardScaler()\n",
    "testXscaled = testscaler.fit_transform(testfreqs)\n",
    "testXscaled = pd.DataFrame(testXscaled, columns = testfreqs.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-ceiling",
   "metadata": {},
   "source": [
    "**Discussion**: why are we scaling these two matrices separately? Why not scale the whole thing together before dividing into test and train sets?\n",
    "\n",
    "**Answer:** That could leak information from the test set into the training set, and would reduce our confidence that we're really \"learning\" — that is, training a model that will generalize to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-cattle",
   "metadata": {},
   "source": [
    "#### cross-validating a model\n",
    "\n",
    "If we just wanted to train and test a single model--and if we only wanted to measure \"accuracy\"--this would be simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "through-campus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.903"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logist = LogisticRegression(C = .1, max_iter = 1000) \n",
    "logist.fit(trainXscaled, train_y)\n",
    "\n",
    "predictions = logist.predict(testXscaled)\n",
    "sum(predictions == test_y) / len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-forum",
   "metadata": {},
   "source": [
    "Why is this not a very safe measurement? Well, how many positive tweets do we actually have in our test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "united-chart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1965"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_y) / len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-quilt",
   "metadata": {},
   "source": [
    "So you can get 80% \"accuracy\" just by predicting \"negative\" in every case.\n",
    "\n",
    "A better measurement is F1 score:\n",
    "\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "The simple way to calculate this is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "random-protest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-investigation",
   "metadata": {},
   "source": [
    "but that doesn't help us understand the number, so ...\n",
    "\n",
    "#### EXERCISE 3:\n",
    "\n",
    "working in small groups, calculate precision: the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. \n",
    "\n",
    "then recall: the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. \n",
    "\n",
    "Then calculate your f1 score, which should equal what *you* got above. Note that since we randomized the test/train split, everyone's result will be slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "decimal-principle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7598 0.7405 0.75\n"
     ]
    }
   ],
   "source": [
    "tp = sum((test_y == 1) & (predictions == 1))\n",
    "fp = sum((test_y == 0) & (predictions == 1))\n",
    "fn = sum((test_y == 1) & (predictions == 0))\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(round(precision, 4), round(recall, 4), round(F1, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-nancy",
   "metadata": {},
   "source": [
    "So this model has higher precision than recall; it's failing to recognize some positive tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-amber",
   "metadata": {},
   "source": [
    "### handling imbalanced classes\n",
    "\n",
    "To keep your model from always choosing \"negative,\" you can weight the classes inversely to their frequency. This will make errors in rare classes more costly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "three-groove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7095 0.7583 0.7331\n"
     ]
    }
   ],
   "source": [
    "logist = LogisticRegression(C = .1, max_iter = 1000, class_weight = 'balanced') \n",
    "logist.fit(trainXscaled, train_y)\n",
    "\n",
    "predictions = logist.predict(testXscaled)\n",
    "\n",
    "tp = sum((test_y == 1) & (predictions == 1))\n",
    "fp = sum((test_y == 0) & (predictions == 1))\n",
    "fn = sum((test_y == 1) & (predictions == 0))\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(round(precision, 4), round(recall, 4), round(F1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-opera",
   "metadata": {},
   "source": [
    "**Note:** This strategy is not guaranteed to improve the overall F1 score in every case. But it probably is significant that it has changed the balance between prevision and recall.\n",
    "\n",
    "The C parameter sets smoothing. It's like alpha in Naive Bayes, except size is reversed here: low numbers equal stronger smoothing. We could fiddle around with C until we got a good number on our test set, but then we might be overfitting our test set. \n",
    "\n",
    "**Discussion:** Why?\n",
    "\n",
    "**Answer:** Again, the problem is that we're leaking some information about the test set into the training process.\n",
    "\n",
    "An alternative is to fiddle around with the *training* set until we get a good C parameter, and then test that number on the test set (being careful not to look at it until the final stage.)\n",
    "\n",
    "But we don't want to overfit the training set in the process of \"fiddling around\" on it. Otherwise we'll tend to choose less regularization than we really need for the test set.\n",
    "\n",
    "A solution here is to \"cross-validate\" on the training set: repeatedly divide it, train on say 4/5th of the data, and test on the remaining fifth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "norman-method",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([1.19712424, 1.04555511, 1.1467638 , 1.0185957 , 1.05130696]), 'score_time': array([0.03987408, 0.03930521, 0.04278016, 0.03945923, 0.04961991]), 'test_score': array([0.74939173, 0.76695438, 0.74905422, 0.73737374, 0.72862454])}\n",
      "\n",
      "Mean f1: 0.7462797203919321\n"
     ]
    }
   ],
   "source": [
    "logist = LogisticRegression(C = .01, max_iter = 1000, class_weight = 'balanced')\n",
    "results = cross_validate(logist, trainXscaled, train_y, cv = 5, scoring = 'f1')\n",
    "print(results)\n",
    "print()\n",
    "print('Mean f1:', np.mean(results['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-ratio",
   "metadata": {},
   "source": [
    "Technically, to be extremely cautious, we would \"scale\" each fold of the cross-validation separately. This can be done in sklearn using a \"pipeline,\" but it adds more complexity than we need for this exercise and doesn't actually change our result greatly.\n",
    "\n",
    "#### EXERCISE 4:\n",
    "\n",
    "Construct a for-loop that tests C parameters ranging from .00001 to 10, varying by powers of 10.\n",
    "\n",
    "    [.00001, .0001, .001, .01, .1, 1, 10]\n",
    "\n",
    "In each case, cross-validate on trainXscaled and report the f1 score. When you've got the C parameter that works best, use that model to make a prediction on testXscaled, and calculate both f1 score and accuracy for that prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "persistent-thanks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C parameter: 1e-05\n",
      "Mean f1: 0.7613891748318042\n",
      "\n",
      "C parameter: 0.0001\n",
      "Mean f1: 0.7631374641196054\n",
      "\n",
      "C parameter: 0.001\n",
      "Mean f1: 0.7660025210823667\n",
      "\n",
      "C parameter: 0.01\n",
      "Mean f1: 0.7462797203919321\n",
      "\n",
      "C parameter: 0.1\n",
      "Mean f1: 0.7297491179145769\n",
      "\n",
      "C parameter: 1\n",
      "Mean f1: 0.7190563121310635\n",
      "\n",
      "C parameter: 10\n",
      "Mean f1: 0.7102743065446762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c_param in [.00001, .0001, .001, .01, .1, 1, 10]:\n",
    "    logist = LogisticRegression(C = c_param, max_iter = 1000, class_weight = 'balanced') \n",
    "    results = cross_validate(logist, trainXscaled, train_y, cv = 5, scoring = 'f1')\n",
    "    print('C parameter:', c_param)\n",
    "    print('Mean f1:', np.mean(results['test_score']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-cinema",
   "metadata": {},
   "source": [
    "So the best C parameter is .001. Now we train a model using that parameter on the whole training set, and see how it performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aggressive-detail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7433 0.7812 0.7618\n"
     ]
    }
   ],
   "source": [
    "logist = LogisticRegression(C = .001, max_iter = 1000, class_weight = 'balanced') \n",
    "logist.fit(trainXscaled, train_y)\n",
    "predictions = logist.predict(testXscaled)\n",
    "\n",
    "tp = sum((test_y == 1) & (predictions == 1))\n",
    "fp = sum((test_y == 0) & (predictions == 1))\n",
    "fn = sum((test_y == 1) & (predictions == 0))\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(round(precision, 4), round(recall, 4), round(F1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-coverage",
   "metadata": {},
   "source": [
    "So F1 measure of .76 is a pretty reliable picture of how well we can separate negative and positive tweets in the future.\n",
    "\n",
    "What if we wanted to interpret this model. Can we extract coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-dollar",
   "metadata": {},
   "source": [
    "#### identify predictive features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "embedded-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "logist = LogisticRegression(C = c_param, max_iter = 1000, class_weight = 'balanced')\n",
    "logist.fit(trainXscaled, train_y)\n",
    "coefficients = [x for x in zip(logist.coef_[0], vectorizer.get_feature_names())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "excited-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "placed-privilege",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1.7117043847030566, 'not'),\n",
       " (-1.6374540241894129, 'worst'),\n",
       " (-1.6030467892361757, 'hour'),\n",
       " (-1.5062158807277217, 'no'),\n",
       " (-1.3533575522349082, 'money'),\n",
       " (-1.3183799823422273, 'delayed'),\n",
       " (-1.3056010947190504, 'bit'),\n",
       " (-1.0414080410457107, 'united'),\n",
       " (-1.0390196286999462, 'luggage'),\n",
       " (-1.0200034060112166, 'hours'),\n",
       " (-0.9900319942873045, 'still'),\n",
       " (-0.9632916046159501, 'let'),\n",
       " (-0.9405220835404323, 'my'),\n",
       " (-0.9364040186855526, 'sucks'),\n",
       " (-0.9216294465734982, 'nothing'),\n",
       " (-0.8914680730617341, 'late'),\n",
       " (-0.8900772316836659, 'rude'),\n",
       " (-0.8853571986426362, 'hung'),\n",
       " (-0.8836141851534709, 'nightmare'),\n",
       " (-0.8573631183855567, 'americanair')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "covered-faith",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7500774026605328, 'best'),\n",
       " (0.7515610516150587, 'proud'),\n",
       " (0.7648435190320645, 'excellent'),\n",
       " (0.8040732038508063, 'jetblue'),\n",
       " (0.8085866899794636, 'kudos'),\n",
       " (0.8130281273154139, 'fun'),\n",
       " (0.8174107124468666, 'made'),\n",
       " (0.8436733372559074, 'beautiful'),\n",
       " (0.8623768551350586, 'loved'),\n",
       " (0.9333926630585165, 'good'),\n",
       " (0.9735490801026193, 'pleasure'),\n",
       " (1.0044545676833794, 'thx'),\n",
       " (1.0597639949059505, 'amazing'),\n",
       " (1.1932485618769935, 'new'),\n",
       " (1.313671612167603, 'appreciate'),\n",
       " (1.6727148661375617, 'awesome'),\n",
       " (2.0363509781665843, 'love'),\n",
       " (2.3797411248727927, 'great'),\n",
       " (3.9116302897781026, 'thank'),\n",
       " (4.576125945294653, 'thanks')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-witness",
   "metadata": {},
   "source": [
    "We can definitely extract coefficients for features. But note that these coefficients are not necessarily easy to interpret. The thing that makes logistic regression stronger than naive Bayes, you'll recall, is that there are no independence assumptions on variables. But this also means that different variables can interact with each other in unpredictable ways. The term you'll hear used for this is \"multicollinearity.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-zoning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
