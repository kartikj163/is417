{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "southern-liberty",
   "metadata": {},
   "source": [
    "# Homework 3: distinctive words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-professional",
   "metadata": {},
   "source": [
    "We calculated distinctive words in movie titles. But there aren't really very many words in movie titles!\n",
    "\n",
    "It would be more fun to do the same thing with movie dialogue.\n",
    "\n",
    "Fortunately we have a dataset available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "golden-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pathlib import Path\n",
    "import math\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mineral-taste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>cid</th>\n",
       "      <th>cname</th>\n",
       "      <th>mname</th>\n",
       "      <th>gender</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>year</th>\n",
       "      <th>genres</th>\n",
       "      <th>comedy</th>\n",
       "      <th>thriller</th>\n",
       "      <th>drama</th>\n",
       "      <th>romance</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>m505</td>\n",
       "      <td>u7468</td>\n",
       "      <td>DEREK</td>\n",
       "      <td>scream 2</td>\n",
       "      <td>m</td>\n",
       "      <td>463</td>\n",
       "      <td>1997</td>\n",
       "      <td>['horror', 'mystery', 'thriller']</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Yeah. / She dumped me. / Not one bit. / Defini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>m151</td>\n",
       "      <td>u2360</td>\n",
       "      <td>MOSS</td>\n",
       "      <td>no country for old men</td>\n",
       "      <td>m</td>\n",
       "      <td>673</td>\n",
       "      <td>2007</td>\n",
       "      <td>['crime', 'drama', 'mystery', 'thriller', 'wes...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>She'll be all right. / No. This works better. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>m322</td>\n",
       "      <td>u4829</td>\n",
       "      <td>MA STONE</td>\n",
       "      <td>the devil and daniel webster</td>\n",
       "      <td>M</td>\n",
       "      <td>795</td>\n",
       "      <td>2004</td>\n",
       "      <td>['comedy', 'drama', 'fantasy']</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>I see you! Riding pretty high, ain't you? Look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>m265</td>\n",
       "      <td>u3979</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>beetle juice</td>\n",
       "      <td>m</td>\n",
       "      <td>945</td>\n",
       "      <td>1988</td>\n",
       "      <td>['comedy', 'fantasy']</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I will &lt;u&gt;never&lt;/u&gt; sell this house. I'll be b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>m316</td>\n",
       "      <td>u4752</td>\n",
       "      <td>DAVE</td>\n",
       "      <td>dave</td>\n",
       "      <td>m</td>\n",
       "      <td>1127</td>\n",
       "      <td>1993</td>\n",
       "      <td>['comedy', 'romance']</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>I'm the President and as they say 'The buck st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mid    cid     cname                         mname gender  wordcount  \\\n",
       "2183  m505  u7468     DEREK                      scream 2      m        463   \n",
       "299   m151  u2360      MOSS        no country for old men      m        673   \n",
       "1240  m322  u4829  MA STONE  the devil and daniel webster      M        795   \n",
       "920   m265  u3979      ADAM                  beetle juice      m        945   \n",
       "1207  m316  u4752      DAVE                          dave      m       1127   \n",
       "\n",
       "      year                                             genres  comedy  \\\n",
       "2183  1997                  ['horror', 'mystery', 'thriller']   False   \n",
       "299   2007  ['crime', 'drama', 'mystery', 'thriller', 'wes...   False   \n",
       "1240  2004                     ['comedy', 'drama', 'fantasy']    True   \n",
       "920   1988                              ['comedy', 'fantasy']    True   \n",
       "1207  1993                              ['comedy', 'romance']    True   \n",
       "\n",
       "      thriller  drama  romance  \\\n",
       "2183      True  False    False   \n",
       "299       True   True    False   \n",
       "1240     False   True    False   \n",
       "920      False  False    False   \n",
       "1207     False  False     True   \n",
       "\n",
       "                                                  lines  \n",
       "2183  Yeah. / She dumped me. / Not one bit. / Defini...  \n",
       "299   She'll be all right. / No. This works better. ...  \n",
       "1240  I see you! Riding pretty high, ain't you? Look...  \n",
       "920   I will <u>never</u> sell this house. I'll be b...  \n",
       "1207  I'm the President and as they say 'The buck st...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogpath = Path('../data/movie_dialogue.tsv')\n",
    "\n",
    "chars = pd.read_csv(dialogpath, sep = '\\t')\n",
    "\n",
    "# let's also randomize the row order\n",
    "chars = chars.sample(frac = 1.0)\n",
    "\n",
    "chars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-grave",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "\n",
    "Find the 25 words that most strongly characterize romance, and the 25 that most strongly characterize dialogue that is not-in-a-romance. \n",
    "\n",
    "1. In doing this, create a CountVectorizer that considers the top *5000* words, not just the top *100* we took for titles. You've got more words to work with now.\n",
    "\n",
    "2. You can use the 'romance' column to divide rows.\n",
    "\n",
    "3. Use the get_dunnings function we developed in the lab to measure Dunning's log-likelihood.\n",
    "\n",
    "Finally report the 25 words at the top, and the bottom, of a list sorted by the Dunning's statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "furnished-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features = 5000)\n",
    "sparse_wordcounts = vectorizer.fit_transform(chars['lines'])\n",
    "wordcounts = sparse_wordcounts.toarray()\n",
    "features = vectorizer.get_feature_names()\n",
    "wordcounts = pd.DataFrame(wordcounts, columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "administrative-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "romantic = wordcounts.loc[chars['romance'] == True, features].sum(axis = 'rows')\n",
    "unromantic = wordcounts.loc[chars['romance'] != True, features].sum(axis = 'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prospective-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dunnings(word, series1, series2):\n",
    "    observed = pd.DataFrame({'series1': [series1[word], sum(series1) - series1[word]],\n",
    "                          'series2': [series2[word], sum(series2) - series2[word]]},\n",
    "                        index = [word, 'all_others'])\n",
    "    total_words = observed.to_numpy().sum()\n",
    "    observed['word_totals'] = observed.sum(axis = 1)\n",
    "    observed = observed.append(observed.sum(axis = 0).rename(index = 'group_totals'))\n",
    "    observed.iat[2,2] = 0\n",
    "    observed['word_totals'] = observed['word_totals'] / sum(observed['word_totals'])\n",
    "    observed.loc['group_totals', : ] = observed.loc['group_totals', : ] / sum(observed.loc['group_totals', : ])\n",
    "    expected = np.outer(observed['word_totals'][0:2], observed.loc['group_totals', : ][0:2])\n",
    "    expected = pd.DataFrame(expected, index = [word, 'all_others'], columns = ['series1', 'series2'])\n",
    "    expected = expected * total_words\n",
    "    \n",
    "    G = 0\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            O = observed.iat[i, j] + .000001\n",
    "            E = expected.iat[i, j] + .000001\n",
    "            G = G + O * math.log(O / E)\n",
    "    \n",
    "    if (observed.iat[0, 0] / sum(observed.iloc[0: 2, 0])) < (observed.iat[0, 1] / sum(observed.iloc[0 : 2, 1])):\n",
    "        G = -G\n",
    "    \n",
    "    return 2 * G, observed, expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "expired-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "dunningslist = []\n",
    "\n",
    "for w in features:\n",
    "    G, observed, expected = get_dunnings(w, romantic, unromantic)\n",
    "    dunningslist.append(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "declared-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "waiting-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "dunnings = pd.Series(dunningslist, index = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "subjective-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "dunnings = dunnings.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ambient-proposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ray         -56.21675\n",
       "theo        -42.28872\n",
       "marty       -41.72248\n",
       "brad        -41.14686\n",
       "roy         -35.06822\n",
       "pete        -34.63867\n",
       "claudia     -34.22905\n",
       "lenny       -32.59347\n",
       "walter      -29.58421\n",
       "diego       -29.00593\n",
       "sergeant    -27.86446\n",
       "west        -27.72823\n",
       "deeds       -27.26712\n",
       "amy         -26.82898\n",
       "lex         -26.68696\n",
       "alvy        -26.10680\n",
       "superman    -25.17840\n",
       "an          -24.85525\n",
       "ned         -24.63396\n",
       "preysing    -24.36632\n",
       "gallagher   -24.36632\n",
       "debbie      -24.09016\n",
       "diz         -23.78617\n",
       "creasy      -23.78617\n",
       "neo         -23.20601\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunnings[0: 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cultural-hardwood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kubelik     32.74856\n",
       "lecter      32.88106\n",
       "marcus      34.16615\n",
       "grail       34.19810\n",
       "jake        34.73883\n",
       "huh         36.28533\n",
       "joanna      37.38169\n",
       "harold      38.20273\n",
       "barton      39.23366\n",
       "thou        44.94803\n",
       "norman      46.78519\n",
       "mulwray     52.36025\n",
       "edie        52.42091\n",
       "mister      55.08855\n",
       "lloyd       57.83746\n",
       "agnes       58.29420\n",
       "mcmurphy    61.86155\n",
       "dil         62.21768\n",
       "toto        64.38499\n",
       "beavis      66.20027\n",
       "dickie      67.72528\n",
       "grace       86.57108\n",
       "sal        106.73629\n",
       "thelma     122.16247\n",
       "heh        189.70823\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunnings[-25 : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-subject",
   "metadata": {},
   "source": [
    "I confess these are not very interpretable features! If you don't immediately see why one set of proper names is associated with romance, and another set isn't -- you're right to be unsure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-respect",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "\n",
    "A. What's the probability $P(character-in-romance)$, for all characters in this dataset?\n",
    "\n",
    "B. What's the conditional probability of a character occurring in a romance, given that the character speaks the word 'you'?\n",
    "\n",
    "In other words, calculate\n",
    "\n",
    "$P(character-in-romance \\mid character-says-you)$\n",
    "\n",
    "Note that both of these questions require a slightly different approach from the probability table we used to calculate Dunnings. The things being counted here are not words, but characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-analysis",
   "metadata": {},
   "source": [
    "#### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sound-doubt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False   0.76255\n",
       "True    0.23745\n",
       "Name: romance, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part A\n",
    "\n",
    "chars['romance'].value_counts() / len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-cinema",
   "metadata": {},
   "source": [
    "P(romance) is 0.23745."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-qualification",
   "metadata": {},
   "source": [
    "#### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "twelve-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "lovechars = chars.loc[wordcounts['love'] > 1, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "diverse-playlist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False   0.73785\n",
       "True    0.26215\n",
       "Name: romance, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovechars['romance'].value_counts() / len(lovechars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-remains",
   "metadata": {},
   "source": [
    "P(romance|says-love) is 0.24653.\n",
    "\n",
    "This is not a huge difference, but it's intuitive that a character's chance of being in a romance is at least slightly higher if they say the word \"love.\"\n",
    "\n",
    "If we wanted a sanity check, we could compare this to evidence from Assignment 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "simple-spirituality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.311183142577576"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunnings['love']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
